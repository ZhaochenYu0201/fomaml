# Meta-Learning for LLM SFT

åŸºäºŽverlæ¡†æž¶çš„å¤§è¯­è¨€æ¨¡åž‹å…ƒå­¦ä¹ ç›‘ç£å¾®è°ƒå®žçŽ°

## ðŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æä¾›äº†å°†Meta-LearningæŠ€æœ¯åº”ç”¨äºŽå¤§è¯­è¨€æ¨¡åž‹SFTçš„å®Œæ•´å®žçŽ°ï¼ŒåŒ…æ‹¬ï¼š

- **MAML-SFT**: Model-Agnostic Meta-Learningçš„LLMé€‚é…ç‰ˆæœ¬ï¼ˆå…¨å‚æ•°ä¼˜åŒ–ï¼‰
- **FOMAML-SFT**: ä¸€é˜¶MAMLè¿‘ä¼¼ï¼Œæ›´é«˜æ•ˆçš„å®žçŽ°ï¼ˆå…¨å‚æ•°ä¼˜åŒ–ï¼‰
- **Reptile-SFT**: æ›´ç®€å•çš„å…ƒå­¦ä¹ ç®—æ³•ï¼Œæ˜“äºŽå®žçŽ°å’Œä½¿ç”¨ï¼ˆå…¨å‚æ•°ä¼˜åŒ–ï¼‰
- **META-LORA**: å‚æ•°é«˜æ•ˆçš„å…ƒå­¦ä¹ æ–¹æ³•ï¼ˆåªä¼˜åŒ–LoRAå‚æ•°ï¼Œ10-100å€é€Ÿåº¦æå‡ï¼‰

åŸºäºŽverlå¼ºåŒ–å­¦ä¹ æ¡†æž¶çš„SFTå®žçŽ°ï¼Œæ”¯æŒFSDPç­‰é«˜æ•ˆè®­ç»ƒæŠ€æœ¯ã€‚

âš ï¸ **é‡è¦è¯´æ˜Ž**ï¼šFOMAML/MAML/Reptileå®žçŽ°æ˜¯**å…¨å‚æ•°ä¼˜åŒ–**ï¼Œä¸ä½¿ç”¨LoRAã€‚å¦‚æžœéœ€è¦å‚æ•°é«˜æ•ˆçš„å…ƒå­¦ä¹ ï¼Œè¯·ä½¿ç”¨**META-LORA**å®žçŽ°ï¼ˆ`meta_lora_trainer.py`ï¼‰ã€‚

## ðŸŽ¯ æ ¸å¿ƒåŠŸèƒ½

### ä¸ºä»€ä¹ˆéœ€è¦Meta-Learning SFTï¼Ÿ

ä¼ ç»ŸSFTçš„å±€é™ï¼š
- éœ€è¦å¤§é‡ç‰¹å®šä»»åŠ¡æ•°æ®
- éš¾ä»¥å¿«é€Ÿé€‚åº”æ–°é¢†åŸŸ
- è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›å¼±

Meta-Learning SFTçš„ä¼˜åŠ¿ï¼š
- âœ… **å¿«é€Ÿé€‚åº”**: åœ¨æ–°ä»»åŠ¡ä¸Šåªéœ€10-50æ¡æ ·æœ¬å³å¯fine-tune
- âœ… **è·¨é¢†åŸŸæ³›åŒ–**: å­¦ä¹ é€šç”¨çš„å­¦ä¹ èƒ½åŠ›
- âœ… **ä¸ªæ€§åŒ–**: å¿«é€Ÿä¸ºä¸åŒç”¨æˆ·/åœºæ™¯å®šåˆ¶æ¨¡åž‹
- âœ… **æ•°æ®æ•ˆçŽ‡**: å¤šä»»åŠ¡å…±äº«çŸ¥è¯†ï¼Œé™ä½Žæ¯ä¸ªä»»åŠ¡çš„æ•°æ®éœ€æ±‚

## ðŸ“ é¡¹ç›®ç»“æž„

```
meta_learning/
â”œâ”€â”€ README.md                          # æœ¬æ–‡ä»¶
â”œâ”€â”€ MAML_SFT_GUIDE.md                 # è¯¦ç»†å®žçŽ°æŒ‡å—
â”œâ”€â”€ maml_sft_trainer.py               # MAML/FOMAMLè®­ç»ƒå™¨ï¼ˆå…¨å‚æ•°ï¼‰
â”œâ”€â”€ meta_lora_trainer.py              # META-LORAè®­ç»ƒå™¨ï¼ˆå‚æ•°é«˜æ•ˆï¼‰â­
â”œâ”€â”€ reptile_sft_trainer.py            # Reptileè®­ç»ƒå™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
â”œâ”€â”€ prepare_maml_data.py              # æ•°æ®å‡†å¤‡è„šæœ¬
â”œâ”€â”€ config_maml_sft_example.yaml      # FOMAMLé…ç½®ç¤ºä¾‹
â”œâ”€â”€ config_meta_lora_example.yaml     # META-LORAé…ç½®ç¤ºä¾‹â­
â”œâ”€â”€ FOMAML_FULL_PARAM_VS_LORA.md     # å…¨å‚æ•° vs LoRAå¯¹æ¯”è¯´æ˜Ž
â”œâ”€â”€ META_LORA_VS_FOMAML_COMPARISON.md # è¯¦ç»†å¯¹æ¯”å®žéªŒæŒ‡å—
â””â”€â”€ verl/                             # verlæ¡†æž¶æºç 
    â”œâ”€â”€ trainer/
    â”‚   â”œâ”€â”€ sft_trainer.py        # verlæ ‡å‡†SFTè®­ç»ƒå™¨
    â”‚   â””â”€â”€ fsdp_sft_trainer.py   # verl FSDP SFTè®­ç»ƒå™¨
    â”œâ”€â”€ utils/
    â”‚   â””â”€â”€ dataset/
    â”‚       â””â”€â”€ sft_dataset.py    # SFTæ•°æ®é›†
    â””â”€â”€ workers/
        â””â”€â”€ roles/utils/
            â””â”€â”€ losses.py         # æŸå¤±å‡½æ•°
```

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. çŽ¯å¢ƒå®‰è£…

```bash
# å…‹éš†verlæ¡†æž¶ï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰
git clone https://github.com/volcengine/verl.git

# å®‰è£…ä¾èµ–
pip install torch transformers pandas pyarrow
pip install -e verl/

# å®‰è£…å…¶ä»–ä¾èµ–
pip install hydra-core omegaconf tensordict wandb
```

### 2. å‡†å¤‡æ•°æ®

#### æ–¹å¼A: ä½¿ç”¨æ•°æ®å‡†å¤‡è„šæœ¬

```bash
# åˆ›å»ºä»»åŠ¡é…ç½®
cat > task_config.json << EOF
{
  "medical": {
    "input_file": "data/medical.parquet",
    "support_ratio": 0.2,
    "max_samples": 5000
  },
  "legal": {
    "input_file": "data/legal.parquet",
    "support_ratio": 0.2,
    "max_samples": 5000
  }
}
EOF

# è¿è¡Œæ•°æ®å‡†å¤‡
python prepare_maml_data.py \
    --config task_config.json \
    --output-dir ./data/maml \
    --balance \
    --support-size 500 \
    --query-size 1000
```

#### æ–¹å¼B: æ‰‹åŠ¨ç»„ç»‡æ•°æ®

ç¡®ä¿æ¯ä¸ªä»»åŠ¡æœ‰ä»¥ä¸‹ç»“æž„ï¼š
```
data/maml/
â”œâ”€â”€ medical/
â”‚   â”œâ”€â”€ support.parquet  # ç”¨äºŽå†…å¾ªçŽ¯é€‚åº”
â”‚   â””â”€â”€ query.parquet    # ç”¨äºŽå…ƒæŸå¤±è®¡ç®—
â”œâ”€â”€ legal/
â”‚   â”œâ”€â”€ support.parquet
â”‚   â””â”€â”€ query.parquet
â””â”€â”€ ...
```

æ•°æ®æ ¼å¼ï¼ˆparquetæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—ï¼‰ï¼š
```python
{
    "prompt": "æ‚£è€…ä¸»è¯‰å¤´ç—›ï¼Œå¦‚ä½•è¯Šæ–­ï¼Ÿ",
    "response": "éœ€è¦è¯¢é—®ç—…å²ã€ä½“æ ¼æ£€æŸ¥..."
}
```

### 3. é…ç½®è®­ç»ƒå‚æ•°

ç¼–è¾‘ `config_maml_sft_example.yaml`:

```yaml
model:
  partial_pretrain: "meta-llama/Llama-3.2-1B"
  use_fsdp: true  # æŽ¨èä½¿ç”¨FSDPå¤„ç†å¤§æ¨¡åž‹
  enable_gradient_checkpointing: true  # é™ä½Žå†…å­˜

meta:
  use_fomaml: true  # æŽ¨èFOMAMLï¼ˆç›¸æ¯”MAMLèŠ‚çœ50%å†…å­˜å’Œæ—¶é—´ï¼‰
  inner_lr: 1e-4
  num_inner_steps: 5
  outer_lr: 3e-5
  meta_batch_size: 4

  tasks:
    - name: "medical"
      support_files: ["data/maml/medical/support.parquet"]
      query_files: ["data/maml/medical/query.parquet"]
    - name: "legal"
      support_files: ["data/maml/legal/support.parquet"]
      query_files: ["data/maml/legal/query.parquet"]

# æ³¨æ„ï¼šè¿™æ˜¯å…¨å‚æ•°FOMAMLé…ç½®
# å¦‚éœ€å‚æ•°é«˜æ•ˆç‰ˆæœ¬ï¼Œè¯·ä½¿ç”¨META-LORAï¼ˆconfig_meta_lora_example.yamlï¼‰
```

### 4. å¯åŠ¨è®­ç»ƒ

#### MAML-SFTè®­ç»ƒ

```bash
# å•å¡
python maml_sft_trainer.py

# å¤šå¡
torchrun --nproc_per_node=4 maml_sft_trainer.py
```

#### Reptile-SFTè®­ç»ƒï¼ˆæŽ¨èæ–°æ‰‹ï¼‰

```bash
# Reptileæ›´ç®€å•ï¼Œå†…å­˜å ç”¨æ›´å°
python reptile_sft_trainer.py
```

#### META-LORAè®­ç»ƒï¼ˆæŽ¨èèµ„æºå—é™åœºæ™¯ï¼‰â­

```bash
# META-LORA: å‚æ•°é«˜æ•ˆ + å¿«é€Ÿè®­ç»ƒ
# åªéœ€30GBå†…å­˜ï¼Œè®­ç»ƒæ—¶é—´ä»…4-6å°æ—¶ï¼ˆvs FOMAMLçš„40-60å°æ—¶ï¼‰

# å•å¡å³å¯è¿è¡Œï¼
python meta_lora_trainer.py --config-name config_meta_lora_example

# å¤šå¡æ›´å¿«
torchrun --nproc_per_node=4 meta_lora_trainer.py --config-name config_meta_lora_example
```

**META-LORAä¼˜åŠ¿ï¼š**
- âœ… åªä¼˜åŒ–LoRAå‚æ•°ï¼ˆ0.1-1%ï¼‰ï¼Œbase modelå®Œå…¨å†»ç»“
- âœ… è®­ç»ƒé€Ÿåº¦å¿«10-100å€
- âœ… åªéœ€100æ ·æœ¬/ä»»åŠ¡ï¼ˆvs FOMAMLçš„300æ ·æœ¬ï¼‰
- âœ… Checkpointè¶…å°ï¼ˆ~10MB vs 2-5GBï¼‰
- âœ… å•å¡A100å³å¯è®­ç»ƒ

è¯¦è§ï¼š[RUN_META_LORA.md](RUN_META_LORA.md) å’Œ [META_LORA_VS_FOMAML_COMPARISON.md](META_LORA_VS_FOMAML_COMPARISON.md)

### 5. ä½¿ç”¨å…ƒå­¦ä¹ çš„æ¨¡åž‹

è®­ç»ƒå®ŒæˆåŽï¼Œå¯ä»¥å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼š

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# åŠ è½½å…ƒå­¦ä¹ çš„æ¨¡åž‹
model = AutoModelForCausalLM.from_pretrained("checkpoints/maml_sft/step_10000")
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.2-1B")

# åœ¨æ–°ä»»åŠ¡ä¸Šå¿«é€Ÿfine-tuneï¼ˆåªéœ€å°‘é‡æ ·æœ¬ï¼ï¼‰
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=1e-4)
new_task_loader = create_dataloader(new_task_data)  # åªéœ€10-50æ¡æ•°æ®

# åªéœ€3-5ä¸ªepoch
for epoch in range(5):
    for batch in new_task_loader:
        loss = compute_loss(model, batch)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

# æ¨¡åž‹å·²ç»é€‚åº”æ–°ä»»åŠ¡ï¼
```

## ðŸ“Š ç®—æ³•å¯¹æ¯”

| ç®—æ³• | ä¼˜åŒ–å‚æ•° | å¤æ‚åº¦ | å†…å­˜å ç”¨ | è®­ç»ƒæ—¶é—´ | æ€§èƒ½ | æŽ¨èåœºæ™¯ |
|------|----------|--------|----------|----------|------|----------|
| **MAML** | 100% | é«˜ | é«˜ (70GB+) | æ…¢ (60h+) | æœ€ä½³ | æ€§èƒ½ä¼˜å…ˆï¼Œèµ„æºå……è¶³ |
| **FOMAML** | 100% | ä¸­ | ä¸­ (70GB+) | ä¸­ (40-60h) | å¾ˆå¥½ | å…¨å‚æ•°å…ƒå­¦ä¹ ï¼Œ4Ã—A100 |
| **Reptile** | 100% | ä½Ž | ä¸­ (50GB+) | å¿« (20-30h) | å¥½ | å¿«é€Ÿå®žéªŒï¼Œç®€å•å®žçŽ° |
| **META-LORA** | 0.1-1% | ä½Ž | ä½Ž (30GB) | **å¾ˆå¿« (4-6h)** | å¾ˆå¥½ | **èµ„æºå—é™ï¼Œå¿«é€Ÿè¿­ä»£** |

âš ï¸ **æ³¨æ„**ï¼šMAML/FOMAML/Reptileéƒ½æ˜¯**å…¨å‚æ•°ä¼˜åŒ–**ã€‚å¦‚æžœèµ„æºæœ‰é™æˆ–éœ€è¦å¿«é€Ÿå®žéªŒï¼Œå¼ºçƒˆæŽ¨èä½¿ç”¨**META-LORA**ã€‚

### ç®—æ³•åŽŸç†ç®€è¿°

#### MAML (Model-Agnostic Meta-Learning)
```python
# åŒå¾ªçŽ¯ç»“æž„
for tasks in meta_batches:
    for task in tasks:
        # å†…å¾ªçŽ¯: åœ¨support setä¸Šé€‚åº”
        Î¸' = Î¸ - Î±âˆ‡L_support(Î¸)

        # å¤–å¾ªçŽ¯: åœ¨query setä¸Šè®¡ç®—å…ƒæŸå¤±
        meta_loss += L_query(Î¸')

    # æ›´æ–°å…ƒå‚æ•°
    Î¸ = Î¸ - Î²âˆ‡meta_loss
```

#### FOMAML (First-Order MAML)
```python
# ä¸ŽMAMLç›¸åŒï¼Œä½†å¿½ç•¥äºŒé˜¶æ¢¯åº¦
# ç”¨ä¸€é˜¶è¿‘ä¼¼æ›¿ä»£å®Œæ•´çš„meta-gradient
Î¸ = Î¸ - Î²âˆ‡Î¸' L_query(Î¸')  # ä¸è®¡ç®— âˆ‚Î¸'/âˆ‚Î¸
```

#### Reptile
```python
# æ›´ç®€å•ï¼šç›´æŽ¥å‘ä»»åŠ¡å‚æ•°ç§»åŠ¨
for task in tasks:
    Î¸_old = Î¸

    # åœ¨ä»»åŠ¡ä¸Šè®­ç»ƒKæ­¥
    for k in range(K):
        Î¸ = Î¸ - Î±âˆ‡L_task(Î¸)

    # æ’å€¼æ›´æ–°
    Î¸ = Î¸_old + Îµ(Î¸ - Î¸_old)
```

## ðŸ”§ verl SFTå®žçŽ°åˆ†æž

### æ ¸å¿ƒç»„ä»¶

```
verlæ¡†æž¶SFTå®žçŽ°:
â”œâ”€â”€ Trainer (sft_trainer.py)
â”‚   â”œâ”€â”€ _build_engine()       # æž„å»ºè®­ç»ƒå¼•æ“Ž
â”‚   â”œâ”€â”€ _build_dataset()      # æž„å»ºæ•°æ®é›†
â”‚   â””â”€â”€ fit()                 # è®­ç»ƒå¾ªçŽ¯
â”‚
â”œâ”€â”€ Dataset (sft_dataset.py)
â”‚   â”œâ”€â”€ è¯»å–parquetæ–‡ä»¶
â”‚   â”œâ”€â”€ åº”ç”¨chat template
â”‚   â”œâ”€â”€ Tokenization
â”‚   â””â”€â”€ åˆ›å»ºloss_mask         # å…³é”®ï¼šåªå¯¹responseè®¡ç®—loss
â”‚
â””â”€â”€ Loss (losses.py)
    â””â”€â”€ sft_loss()            # masked cross-entropy loss
```

### å…³é”®å®žçŽ°ç»†èŠ‚

#### 1. Loss Masking
```python
# verl/workers/roles/utils/losses.py:27-53
def sft_loss(config, model_output, data, dp_group=None):
    log_prob = model_output["log_probs"]
    loss_mask = data["loss_mask"]  # promptéƒ¨åˆ†ä¸º0ï¼Œresponseéƒ¨åˆ†ä¸º1

    # åªè®¡ç®—responseçš„æŸå¤±
    loss = -masked_sum(log_prob, loss_mask) / batch_num_tokens
    return loss
```

#### 2. æ•°æ®æ ¼å¼
```python
# verl/utils/dataset/sft_dataset.py:136-204
def __getitem__(self, item):
    prompt = self.prompts[item]
    response = self.responses[item]

    # åº”ç”¨chat template
    prompt_str = tokenizer.apply_chat_template([{"role": "user", "content": prompt}])

    # åˆ›å»ºloss_mask
    loss_mask = attention_mask.clone()
    loss_mask[:prompt_length-1] = 0  # maskæŽ‰prompt

    return {
        'input_ids': input_ids,
        'attention_mask': attention_mask,
        'position_ids': position_ids,
        'loss_mask': loss_mask,
    }
```

## ðŸŽ“ å®žçŽ°è¦ç‚¹

### 1. MAML-SFTå…³é”®ç‚¹

```python
class MAMLSFTTrainer:
    def _meta_update_step(self, task_batch):
        # ä¿å­˜åŽŸå§‹å‚æ•°
        original_params = clone_params(self.model)

        for task in task_batch:
            # å†…å¾ªçŽ¯ï¼šåœ¨support setä¸Šé€‚åº”
            for k in range(self.num_inner_steps):
                loss = sft_loss(support_batch)
                grads = compute_grads(loss, create_graph=not use_fomaml)
                update_params(grads, lr=inner_lr)

            # å¤–å¾ªçŽ¯ï¼šåœ¨query setä¸Šè®¡ç®—æŸå¤±
            query_loss = sft_loss(query_batch)
            meta_loss += query_loss

            # æ¢å¤åŽŸå§‹å‚æ•°
            restore_params(original_params)

        # å…ƒæ¢¯åº¦æ›´æ–°
        meta_loss.backward()
        meta_optimizer.step()
```

### 2. ä¸Žverl SFTçš„å…¼å®¹æ€§

æˆ‘ä»¬çš„å®žçŽ°å®Œå…¨å…¼å®¹verlçš„SFTæ•°æ®æ ¼å¼å’ŒæŸå¤±è®¡ç®—ï¼š

```python
# ä½¿ç”¨verlçš„SFTæ•°æ®é›†
from verl.utils.dataset import SFTDataset

dataset = SFTDataset(
    parquet_files=data_files,
    tokenizer=tokenizer,
    config=data_config
)

# ä½¿ç”¨verlçš„æŸå¤±è®¡ç®—é€»è¾‘
def _compute_sft_loss(self, batch, model):
    # ä¸Žverl/workers/roles/utils/losses.pyä¸­çš„sft_lossç›¸åŒ
    log_prob = compute_log_prob(model, batch)
    loss_mask = batch["loss_mask"]
    loss = -masked_sum(log_prob, loss_mask) / num_tokens
    return loss
```

## ðŸ’¡ ä¼˜åŒ–å»ºè®®

### å†…å­˜ä¼˜åŒ–

âš ï¸ **é‡è¦**ï¼šFOMAMLæ˜¯å…¨å‚æ•°ä¼˜åŒ–ï¼Œå†…å­˜éœ€æ±‚è¾ƒé«˜ï¼ˆ~70GBï¼‰ã€‚å¦‚æžœå†…å­˜ä¸è¶³ï¼ŒæŽ¨èä½¿ç”¨**META-LORA**ï¼ˆåªéœ€30GBï¼‰ã€‚

```yaml
# 1. ä½¿ç”¨FOMAMLï¼ˆç›¸æ¯”MAMLèŠ‚çœ50%ï¼‰
meta:
  use_fomaml: true

# 2. ä½¿ç”¨META-LORAï¼ˆç›¸æ¯”FOMAMLèŠ‚çœ50%ä»¥ä¸Šï¼‰
# è§ meta_lora_trainer.py å’Œ config_meta_lora_example.yaml

# 3. å‡å°batch size
meta:
  inner_batch_size: 2
  query_batch_size: 2
  meta_batch_size: 2

# 4. æ¢¯åº¦æ£€æŸ¥ç‚¹
model:
  enable_gradient_checkpointing: true

# 5. ä½¿ç”¨FSDP
model:
  use_fsdp: true
```

### é€Ÿåº¦ä¼˜åŒ–
```yaml
# 1. å‡å°‘å†…å¾ªçŽ¯æ­¥æ•°
meta:
  num_inner_steps: 3  # ä»Ž5é™åˆ°3

# 2. Flash Attention
model:
  attn_implementation: "flash_attention_2"

# 3. ä½¿ç”¨Reptileï¼ˆæ›´å¿«ï¼‰
# python reptile_sft_trainer.py
```

### æ€§èƒ½ä¼˜åŒ–
```yaml
# 1. è°ƒæ•´å­¦ä¹ çŽ‡æ¯”ä¾‹
meta:
  inner_lr: 1e-4
  outer_lr: 3e-5  # inner_lr / outer_lr â‰ˆ 3-5

# 2. è¶³å¤Ÿçš„å†…å¾ªçŽ¯æ­¥æ•°
meta:
  num_inner_steps: 5  # é€šå¸¸5-10æ­¥

# 3. é«˜è´¨é‡support set
# ç²¾å¿ƒæŒ‘é€‰æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬
```

## ðŸ“š è¯¦ç»†æ–‡æ¡£

- **[MAML_SFT_GUIDE.md](MAML_SFT_GUIDE.md)**: å®Œæ•´çš„å®žçŽ°æŒ‡å—
  - ç†è®ºèƒŒæ™¯
  - å®žçŽ°ç»†èŠ‚
  - ä¼˜åŒ–æŠ€å·§
  - æ•…éšœæŽ’é™¤
  - å®žéªŒå»ºè®®

- **ä»£ç æ–‡ä»¶**:
  - `maml_sft_trainer.py`: MAML/FOMAMLå®Œæ•´å®žçŽ°
  - `reptile_sft_trainer.py`: Reptileç®€åŒ–å®žçŽ°
  - `prepare_maml_data.py`: æ•°æ®å‡†å¤‡å·¥å…·

## ðŸ”¬ å®žéªŒå»ºè®®

### åŸºå‡†å®žéªŒ

```python
# å®žéªŒ1: éªŒè¯å…ƒå­¦ä¹ æœ‰æ•ˆæ€§
baselines = {
    'standard_sft': train_on_all_tasks(),
    'maml_sft': meta_train_then_adapt(),
    'fomaml_sft': meta_train_then_adapt(use_fomaml=True),
    'reptile_sft': reptile_train_then_adapt(),
}

# è¯„ä¼°: Few-shoté€‚åº”æ€§èƒ½
for n_shots in [10, 50, 100]:
    for method, model in baselines.items():
        adapted_model = adapt(model, n_shots)
        performance = evaluate(adapted_model)
```

### è¶…å‚æ•°æœç´¢

```python
# å…³é”®è¶…å‚æ•°
hyperparams = {
    'inner_lr': [1e-5, 1e-4, 1e-3],
    'outer_lr': [1e-5, 3e-5, 1e-4],
    'num_inner_steps': [1, 3, 5, 10],
    'meta_batch_size': [2, 4, 8],
}
```

## ðŸ¤ å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. **MAML**: Finn et al. "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks" (ICML 2017)
2. **FOMAML**: Finn et al. "On First-Order Meta-Learning Algorithms" (2018)
3. **Reptile**: Nichol et al. "Reptile: A Scalable Meta-Learning Algorithm" (2018)

### ä»£ç 
- verlæ¡†æž¶: https://github.com/volcengine/verl
- learn2learn: https://github.com/learnables/learn2learn
- higher: https://github.com/facebookresearch/higher

## ðŸ“§ é—®é¢˜åé¦ˆ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹ [MAML_SFT_GUIDE.md](MAML_SFT_GUIDE.md) ä¸­çš„æ•…éšœæŽ’é™¤éƒ¨åˆ†
2. æ£€æŸ¥ä»£ç æ³¨é‡Š
3. å‚è€ƒverlæ¡†æž¶æ–‡æ¡£

## ðŸ“„ License

æœ¬é¡¹ç›®åŸºäºŽverlæ¡†æž¶å®žçŽ°ï¼Œéµå¾ªApache 2.0 Licenseã€‚

---

**ç¥å®žéªŒé¡ºåˆ©ï¼ðŸš€**

å¦‚æžœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿Žstarå’Œåˆ†äº«ï¼
