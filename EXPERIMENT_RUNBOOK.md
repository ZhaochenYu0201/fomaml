# FOMAML-SFTå®Œæ•´å®éªŒè¿è¡Œæ‰‹å†Œ

## ç›®æ ‡

éªŒè¯FOMAML-SFTåœ¨æ•°å­¦å’Œç§‘å­¦æ¨ç†ä»»åŠ¡ä¸Šç›¸æ¯”æ ‡å‡†SFTçš„few-shotå­¦ä¹ ä¼˜åŠ¿ã€‚

---

## å®éªŒæµç¨‹æ€»è§ˆ

```
Step 1: æ•°æ®å‡†å¤‡ (1-2å¤©)
   â†“
Step 2: Baselineè®­ç»ƒ (2-3å¤©)
   â†“
Step 3: FOMAML-SFTè®­ç»ƒ (3-5å¤©)
   â†“
Step 4: Few-Shotè¯„ä¼° (2-3å¤©)
   â†“
Step 5: ç»“æœåˆ†æ (1-2å¤©)
```

**æ€»è®¡ï¼š9-15å¤©**

---

## Step 1: æ•°æ®å‡†å¤‡

### 1.1 å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ç¯å¢ƒ
pip install torch transformers datasets pandas pyarrow numpy scipy matplotlib seaborn tqdm

# verlæ¡†æ¶
git clone https://github.com/volcengine/verl.git
cd verl
pip install -e .
cd ..

# å…¶ä»–ä¾èµ–
pip install hydra-core omegaconf tensordict wandb pyyaml
```

### 1.2 è¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬

```bash
# å‡†å¤‡æ‰€æœ‰æ•°æ®é›†ï¼ˆæ¨èï¼‰
python prepare_math_science_data.py \
    --output-dir ./data/math_science_meta \
    --seed 42 \
    --support-ratio 0.2 \
    --query-ratio 0.3

# è¿™ä¼šåˆ›å»ºä»¥ä¸‹ç»“æ„ï¼š
# data/math_science_meta/
# â”œâ”€â”€ meta_train/
# â”‚   â”œâ”€â”€ algebra_support.parquet
# â”‚   â”œâ”€â”€ algebra_query.parquet
# â”‚   â”œâ”€â”€ geometry_support.parquet
# â”‚   â”œâ”€â”€ geometry_query.parquet
# â”‚   â””â”€â”€ ... (å…¶ä»–ä»»åŠ¡)
# â”œâ”€â”€ few_shot_eval/
# â”‚   â”œâ”€â”€ algebra_test.parquet
# â”‚   â”œâ”€â”€ algebra_5shot.parquet
# â”‚   â”œâ”€â”€ algebra_10shot.parquet
# â”‚   â””â”€â”€ ... (å…¶ä»–ä»»åŠ¡å’Œshotæ•°)
# â”œâ”€â”€ baseline_sft_all_mixed.parquet  # Baseline SFTè®­ç»ƒæ•°æ®
# â”œâ”€â”€ config_fomaml_math_science.yaml  # FOMAMLé…ç½®
# â””â”€â”€ config_baseline_sft.yaml         # Baselineé…ç½®
```

### 1.3 éªŒè¯æ•°æ®

```bash
# æ£€æŸ¥æ•°æ®ç»Ÿè®¡
python -c "
import pandas as pd
from pathlib import Path

data_dir = Path('./data/math_science_meta/meta_train')
for file in sorted(data_dir.glob('*_support.parquet')):
    df = pd.read_parquet(file)
    print(f'{file.name}: {len(df)} samples')
    print(f'  Columns: {df.columns.tolist()}')
    print(f'  Example prompt length: {len(df.iloc[0][\"prompt\"])} chars')
    print()
"
```

**é¢„æœŸè¾“å‡ºï¼š**
```
algebra_support.parquet: ~300 samples
  Columns: ['prompt', 'response', 'metadata']
  Example prompt length: ~200 chars

geometry_support.parquet: ~250 samples
...
```

---

## Step 2: Baseline SFTè®­ç»ƒ

### 2.1 ä½¿ç”¨verlè®­ç»ƒBaseline SFT

```bash
# å•GPU
python verl/verl/trainer/sft_trainer.py \
    --config-path ../data/math_science_meta \
    --config-name config_baseline_sft

# å¤šGPU (4å¡)
torchrun --nproc_per_node=4 \
    verl/verl/trainer/sft_trainer.py \
    --config-path ../data/math_science_meta \
    --config-name config_baseline_sft
```

### 2.2 ç›‘æ§è®­ç»ƒ

```python
# ä½¿ç”¨wandbç›‘æ§
# å…³é”®æŒ‡æ ‡ï¼š
# - train/loss: åº”è¯¥æŒç»­ä¸‹é™
# - train/lr: å­¦ä¹ ç‡æ›²çº¿
# - val/loss: éªŒè¯é›†æŸå¤±

# é¢„æœŸï¼š
# - è®­ç»ƒloss: ä»~2.5é™åˆ°~0.5-1.0
# - å¤§çº¦éœ€è¦3 epochsï¼Œ~5000 steps
# - 4å¡A100çº¦2-3å°æ—¶
```

### 2.3 ä¿å­˜Baseline checkpoint

```bash
# Checkpointä¿å­˜åœ¨:
# ./checkpoints/baseline_sft/global_step_XXXX/
```

---

## Step 3: FOMAML-SFTè®­ç»ƒ

### 3.1 å¯åŠ¨FOMAML-SFTè®­ç»ƒ

```bash
# å•GPU (ä¸æ¨èï¼Œå†…å­˜å¯èƒ½ä¸å¤Ÿ)
python maml_sft_trainer.py \
    --config-path data/math_science_meta \
    --config-name config_fomaml_math_science

# å¤šGPU (4å¡ï¼Œæ¨è)
torchrun --nproc_per_node=4 \
    maml_sft_trainer.py \
    --config-path data/math_science_meta \
    --config-name config_fomaml_math_science
```

### 3.2 FOMAMLè®­ç»ƒç›‘æ§

```python
# å…³é”®æŒ‡æ ‡ï¼ˆwandbï¼‰:

# Meta-levelæŒ‡æ ‡:
# - meta/loss: å…ƒæŸå¤±ï¼Œåº”è¯¥ä¸‹é™
# - meta/grad_norm: æ¢¯åº¦èŒƒæ•°

# Task-specificæŒ‡æ ‡:
# - {task_name}/support_loss: å†…å¾ªç¯support loss
# - {task_name}/query_loss: å¤–å¾ªç¯query loss
# - {task_name}/adaptation_gap: query_loss - support_loss

# å¥åº·è®­ç»ƒçš„æ ‡å¿—:
# 1. meta/loss æŒç»­ä¸‹é™
# 2. adaptation_gap é€æ¸å‡å°ï¼ˆè¯´æ˜å…ƒåˆå§‹åŒ–å˜å¥½ï¼‰
# 3. ä¸åŒä»»åŠ¡çš„query_lossç›¸å¯¹å¹³è¡¡
```

### 3.3 é¢„æœŸè®­ç»ƒæ—¶é—´å’Œèµ„æº

```
é…ç½®: 4Ã—A100 (80GB)
æ¨¡å‹: Llama-3.2-1B with LoRA (rank=16)
ä»»åŠ¡æ•°: 6-8ä¸ª

é¢„æœŸ:
- æ¯ä¸ªmeta-iteration: ~30-60ç§’
- 5000 steps: ~42-83å°æ—¶ (2-3.5å¤©)
- å³°å€¼å†…å­˜: æ¯GPU ~40-50GB
- å¯ç”¨æ¢¯åº¦accumulationå‡å°‘å†…å­˜
```

### 3.4 æ•…éšœæ’é™¤

```bash
# é—®é¢˜1: OOM (å†…å­˜ä¸è¶³)
è§£å†³æ–¹æ¡ˆ:
1. å‡å°meta_batch_size: 3 â†’ 2
2. å‡å°inner_batch_size: 4 â†’ 2
3. å‡å°num_inner_steps: 5 â†’ 3
4. å¯ç”¨gradient checkpointing
5. ä½¿ç”¨æ›´å°çš„LoRA rank: 16 â†’ 8

# é—®é¢˜2: è®­ç»ƒä¸ç¨³å®š (losséœ‡è¡)
è§£å†³æ–¹æ¡ˆ:
1. é™ä½inner_lr: 5e-5 â†’ 1e-5
2. é™ä½outer_lr: 2e-5 â†’ 1e-5
3. å¢åŠ æ¢¯åº¦è£å‰ª: clip_grad=0.5
4. æ£€æŸ¥æ•°æ®è´¨é‡

# é—®é¢˜3: é€‚åº”æ•ˆæœå·® (adaptation_gapä¸å‡å°)
è§£å†³æ–¹æ¡ˆ:
1. å¢åŠ num_inner_steps: 5 â†’ 10
2. æ£€æŸ¥ä»»åŠ¡ç›¸å…³æ€§ï¼ˆä»»åŠ¡æ˜¯å¦çœŸçš„ç›¸å…³ï¼‰
3. å¢åŠ support setå¤§å°
4. è®­ç»ƒæ›´å¤šsteps
```

---

## Step 4: Few-Shotè¯„ä¼°

### 4.1 è¯„ä¼°Baseline SFT

```bash
python evaluate_few_shot.py \
    --model-path ./checkpoints/baseline_sft/global_step_5000 \
    --model-type sft \
    --data-dir ./data/math_science_meta/few_shot_eval \
    --eval-tasks algebra geometry number_theory word_problems \
    --n-shots 0 5 10 25 50 \
    --n-runs 5 \
    --output-dir ./results/baseline_sft \
    --adaptation-lr 1e-4 \
    --adaptation-steps 100

# è¿™ä¼šï¼š
# 1. å¯¹æ¯ä¸ªä»»åŠ¡åœ¨ä¸åŒfew-shotè®¾ç½®ä¸‹è¯„ä¼°
# 2. é‡å¤5æ¬¡å–å¹³å‡ï¼ˆå‡å°‘éšæœºæ€§ï¼‰
# 3. ç”Ÿæˆå­¦ä¹ æ›²çº¿å›¾
# 4. ä¿å­˜ç»“æœåˆ° results/baseline_sft/sft_results.json
```

### 4.2 è¯„ä¼°FOMAML-SFT

```bash
python evaluate_few_shot.py \
    --model-path ./checkpoints/fomaml_math_science/maml_checkpoint_step_5000.pt \
    --model-type fomaml \
    --data-dir ./data/math_science_meta/few_shot_eval \
    --eval-tasks algebra geometry number_theory word_problems \
    --n-shots 0 5 10 25 50 \
    --n-runs 5 \
    --output-dir ./results/fomaml_sft \
    --adaptation-lr 1e-4 \
    --adaptation-steps 100
```

### 4.3 Base Modelè¯„ä¼°ï¼ˆå¯é€‰ï¼‰

```bash
# è¯„ä¼°æœªfine-tuneçš„base modelä½œä¸ºä¸‹ç•Œå‚è€ƒ
python evaluate_few_shot.py \
    --model-path meta-llama/Llama-3.2-1B \
    --model-type base \
    --data-dir ./data/math_science_meta/few_shot_eval \
    --eval-tasks algebra geometry number_theory word_problems \
    --n-shots 0 5 10 25 50 \
    --n-runs 5 \
    --output-dir ./results/base_model
```

### 4.4 è¯„ä¼°æ—¶é—´ä¼°ç®—

```
å•ä»»åŠ¡å•ä¸ªfew-shotè®¾ç½®å•æ¬¡è¿è¡Œï¼š
- Zero-shot (0-shot): ~5åˆ†é’Ÿ (100 samples)
- 5-shot: ~10åˆ†é’Ÿ (adapt 100 steps + eval 100 samples)
- 10-shot: ~10åˆ†é’Ÿ
- 25-shot: ~15åˆ†é’Ÿ
- 50-shot: ~20åˆ†é’Ÿ

æ€»è®¡å•ä»»åŠ¡5ä¸ªè®¾ç½®5æ¬¡è¿è¡Œ: ~4-5å°æ—¶

4ä¸ªä»»åŠ¡ Ã— 5å°æ—¶ = 20å°æ—¶

3ä¸ªæ¨¡å‹ Ã— 20å°æ—¶ = 60å°æ—¶ (2.5å¤©)

å¹¶è¡Œè¯„ä¼°å¯å¤§å¹…åŠ é€Ÿï¼
```

---

## Step 5: ç»“æœåˆ†æ

### 5.1 æ¯”è¾ƒå­¦ä¹ æ›²çº¿

```bash
# åˆ›å»ºå¯¹æ¯”å›¾
python -c "
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# åŠ è½½ç»“æœ
with open('results/fomaml_sft/fomaml_results.json') as f:
    fomaml_results = json.load(f)

with open('results/baseline_sft/sft_results.json') as f:
    sft_results = json.load(f)

# ä¸ºæ¯ä¸ªä»»åŠ¡ç»˜åˆ¶å¯¹æ¯”å›¾
for task in fomaml_results.keys():
    fig, ax = plt.subplots(figsize=(10, 6))

    # FOMAML curve
    fomaml_shots = sorted([int(k) for k in fomaml_results[task].keys()])
    fomaml_accs = [fomaml_results[task][str(s)]['accuracy_mean'] * 100 for s in fomaml_shots]

    # SFT curve
    sft_shots = sorted([int(k) for k in sft_results[task].keys()])
    sft_accs = [sft_results[task][str(s)]['accuracy_mean'] * 100 for s in sft_shots]

    ax.plot(fomaml_shots, fomaml_accs, marker='o', label='FOMAML-SFT', linewidth=2)
    ax.plot(sft_shots, sft_accs, marker='s', label='Baseline SFT', linewidth=2)

    ax.set_xlabel('Number of Few-Shot Examples', fontsize=12)
    ax.set_ylabel('Accuracy (%)', fontsize=12)
    ax.set_title(f'{task} - Few-Shot Learning Curve', fontsize=14)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'results/comparison_{task}.png', dpi=300)
    print(f'Saved: results/comparison_{task}.png')
"
```

### 5.2 è®¡ç®—æ ·æœ¬æ•ˆç‡

```python
# è®¡ç®—è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡æ‰€éœ€çš„æ ·æœ¬æ•°
def compute_sample_efficiency(results, target_acc=0.7):
    \"\"\"è®¡ç®—è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡éœ€è¦çš„æ ·æœ¬æ•°\"\"\"
    for n_shots in sorted(results.keys(), key=int):
        acc = results[n_shots]['accuracy_mean']
        if acc >= target_acc:
            return int(n_shots)
    return float('inf')

# å¯¹æ¯”
target = 0.7  # 70%å‡†ç¡®ç‡
for task in fomaml_results.keys():
    fomaml_samples = compute_sample_efficiency(fomaml_results[task], target)
    sft_samples = compute_sample_efficiency(sft_results[task], target)

    efficiency_gain = sft_samples / fomaml_samples if fomaml_samples < float('inf') else float('inf')

    print(f"{task}:")
    print(f"  FOMAML-SFT: {fomaml_samples} samples to reach {target:.0%}")
    print(f"  Baseline SFT: {sft_samples} samples to reach {target:.0%}")
    print(f"  Efficiency gain: {efficiency_gain:.1f}x")
    print()
```

### 5.3 ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

```python
from scipy import stats

# å¯¹æ¯ä¸ªä»»åŠ¡çš„æ¯ä¸ªfew-shotè®¾ç½®è¿›è¡Œé…å¯¹tæ£€éªŒ
for task in fomaml_results.keys():
    print(f"\n{task}:")

    for n_shots in fomaml_results[task].keys():
        # å‡è®¾æˆ‘ä»¬ä¿å­˜äº†å¤šæ¬¡è¿è¡Œçš„æ‰€æœ‰ç»“æœ
        fomaml_runs = fomaml_results[task][n_shots].get('runs', [])
        sft_runs = sft_results[task][n_shots].get('runs', [])

        if len(fomaml_runs) > 1 and len(sft_runs) > 1:
            fomaml_accs = [r['accuracy'] for r in fomaml_runs]
            sft_accs = [r['accuracy'] for r in sft_runs]

            # é…å¯¹tæ£€éªŒ
            t_stat, p_value = stats.ttest_ind(fomaml_accs, sft_accs)

            fomaml_mean = np.mean(fomaml_accs)
            sft_mean = np.mean(sft_accs)
            diff = fomaml_mean - sft_mean

            sig = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"

            print(f"  {n_shots}-shot:")
            print(f"    FOMAML: {fomaml_mean:.2%}, SFT: {sft_mean:.2%}")
            print(f"    Diff: {diff:+.2%}, p={p_value:.4f} {sig}")
```

### 5.4 ç”Ÿæˆå®éªŒæŠ¥å‘Š

```python
# åˆ›å»ºLaTeXè¡¨æ ¼
print("\\begin{table}[h]")
print("\\centering")
print("\\caption{Few-Shot Learning Performance Comparison}")
print("\\begin{tabular}{lcccccc}")
print("\\toprule")
print("Task & Method & 0-shot & 5-shot & 10-shot & 25-shot & 50-shot \\\\")
print("\\midrule")

for task in fomaml_results.keys():
    # FOMAML row
    fomaml_row = [task, "FOMAML-SFT"]
    for n in [0, 5, 10, 25, 50]:
        acc = fomaml_results[task][str(n)]['accuracy_mean']
        fomaml_row.append(f"{acc:.2%}")
    print(" & ".join(fomaml_row) + " \\\\")

    # SFT row
    sft_row = ["", "Baseline SFT"]
    for n in [0, 5, 10, 25, 50]:
        acc = sft_results[task][str(n)]['accuracy_mean']
        sft_row.append(f"{acc:.2%}")
    print(" & ".join(sft_row) + " \\\\")

    print("\\midrule")

print("\\bottomrule")
print("\\end{tabular}")
print("\\end{table}")
```

---

## é¢„æœŸç»“æœ

### æˆåŠŸæ ‡å‡†

âœ… **ä¸»è¦æˆåŠŸæ ‡å‡†ï¼š**

1. **æ ·æœ¬æ•ˆç‡æå‡ â‰¥ 3å€**
   ```
   è¾¾åˆ°70%å‡†ç¡®ç‡æ‰€éœ€æ ·æœ¬ï¼š
   FOMAML-SFT: 10 shots
   Baseline SFT: 30+ shots
   æ•ˆç‡æ¯”: 3x+
   ```

2. **Zero-shotè¿ç§»æå‡ â‰¥ 5%**
   ```
   åœ¨æœªè§è¿‡ä»»åŠ¡ä¸Šçš„zero-shotå‡†ç¡®ç‡ï¼š
   FOMAML-SFT: 45%
   Baseline SFT: 40%
   æå‡: +5%
   ```

3. **ç»Ÿè®¡æ˜¾è‘—æ€§ p < 0.05**
   ```
   åœ¨å¤šä¸ªä»»åŠ¡å’Œfew-shotè®¾ç½®ä¸‹ä¸€è‡´æ˜¾è‘—
   ```

### é¢„æœŸå­¦ä¹ æ›²çº¿å½¢çŠ¶

```
Accuracy (%)
   100 â”¤
       â”‚
    80 â”¤                        â—â”€â”€â”€â— FOMAML-SFT
       â”‚                    â—â”€â”€â—
    60 â”¤               â—â”€â”€â—          â—‹â”€â”€â”€â—‹ Baseline SFT
       â”‚          â—â”€â”€â—           â—‹â”€â”€â—‹
    40 â”¤     â—â”€â”€â—           â—‹â”€â”€â—‹
       â”‚  â—â”€â”€               â—‹
    20 â”¤â—               â—‹
       â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€> N-shot
           0   5  10  25  50  100

å…³é”®ç‰¹å¾ï¼š
1. FOMAML-SFTèµ·ç‚¹æ›´é«˜ï¼ˆbetter zero-shotï¼‰
2. FOMAML-SFTä¸Šå‡æ›´å¿«ï¼ˆbetter few-shot learningï¼‰
3. FOMAML-SFTåœ¨5-10 shotæ—¶å·²è¾¾åˆ°è¾ƒé«˜æ€§èƒ½
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜1: FOMAML-SFTæ•ˆæœä¸å¦‚SFT

**å¯èƒ½åŸå› ï¼š**
1. ä»»åŠ¡é—´ç›¸å…³æ€§ä¸å¤Ÿ
2. è¶…å‚æ•°ä¸åˆé€‚
3. è®­ç»ƒä¸å……åˆ†

**è¯Šæ–­æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥ä»»åŠ¡ç›¸ä¼¼åº¦
python -c "
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# è®¡ç®—ä»»åŠ¡é—´çš„æ–‡æœ¬ç›¸ä¼¼åº¦
tasks_data = {}
for task in ['algebra', 'geometry', 'number_theory']:
    df = pd.read_parquet(f'data/meta_train/{task}_support.parquet')
    tasks_data[task] = ' '.join(df['prompt'].tolist()[:100])

vectorizer = TfidfVectorizer()
vectors = vectorizer.fit_transform(tasks_data.values())
similarity = cosine_similarity(vectors)

print('Task Similarity Matrix:')
print(similarity)
# å¦‚æœç›¸ä¼¼åº¦ < 0.3ï¼Œä»»åŠ¡å¯èƒ½å¤ªä¸ç›¸å…³
"

# 2. æ£€æŸ¥meta-trainingæŒ‡æ ‡
# æŸ¥çœ‹ adaptation_gap æ˜¯å¦åœ¨ä¸‹é™
# å¦‚æœä¸ä¸‹é™ï¼Œè¯´æ˜meta-learningæ²¡æœ‰å­¦åˆ°å¥½çš„åˆå§‹åŒ–

# 3. å°è¯•ä¸åŒè¶…å‚æ•°
# inner_lr: [1e-5, 5e-5, 1e-4]
# num_inner_steps: [3, 5, 10]
# outer_lr: [1e-5, 2e-5, 5e-5]
```

### é—®é¢˜2: è¯„ä¼°ç»“æœæ–¹å·®å¤ªå¤§

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¢åŠ è¯„ä¼°é‡å¤æ¬¡æ•°
--n-runs 10  # ä»3å¢åŠ åˆ°10

# å›ºå®šéšæœºç§å­
--seed 42

# ä½¿ç”¨æ›´å¤šæµ‹è¯•æ ·æœ¬
# ä¿®æ”¹evaluate_few_shot.pyä¸­çš„test_data[:100]ä¸ºtest_data[:500]
```

### é—®é¢˜3: è®­ç»ƒæ—¶é—´å¤ªé•¿

**åŠ é€Ÿæ–¹æ¡ˆï¼š**
```bash
# 1. å‡å°‘ä»»åŠ¡æ•°é‡
# ä»8ä¸ªå‡åˆ°5-6ä¸ªæ ¸å¿ƒä»»åŠ¡

# 2. å‡å°‘è®­ç»ƒæ­¥æ•°
# 5000 â†’ 3000 stepsï¼ˆå¯èƒ½ç‰ºç‰²å°‘è®¸æ€§èƒ½ï¼‰

# 3. å‡å°‘å†…å¾ªç¯æ­¥æ•°
# num_inner_steps: 5 â†’ 3

# 4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
# Llama-3.2-1B â†’ Qwen2.5-0.5B

# 5. å¹¶è¡Œè¯„ä¼°
# åœ¨å¤šä¸ªGPUä¸Šå¹¶è¡Œè¯„ä¼°ä¸åŒä»»åŠ¡
```

---

## Checklist

### æ•°æ®å‡†å¤‡
- [ ] ä¸‹è½½æ•°æ®é›† (MATH, GSM8K, ScienceQA)
- [ ] è¿è¡Œ `prepare_math_science_data.py`
- [ ] éªŒè¯æ•°æ®æ ¼å¼å’Œç»Ÿè®¡
- [ ] æ£€æŸ¥ç”Ÿæˆçš„é…ç½®æ–‡ä»¶

### Baselineè®­ç»ƒ
- [ ] å¯åŠ¨Baseline SFTè®­ç»ƒ
- [ ] ç›‘æ§è®­ç»ƒæŒ‡æ ‡
- [ ] ä¿å­˜checkpoint
- [ ] è®°å½•è®­ç»ƒæ—¶é—´å’Œèµ„æº

### FOMAMLè®­ç»ƒ
- [ ] å¯åŠ¨FOMAML-SFTè®­ç»ƒ
- [ ] ç›‘æ§meta-trainingæŒ‡æ ‡
- [ ] æ£€æŸ¥adaptation_gapè¶‹åŠ¿
- [ ] ä¿å­˜æœ€ä½³checkpoint

### è¯„ä¼°
- [ ] è¯„ä¼°Base Model
- [ ] è¯„ä¼°Baseline SFT
- [ ] è¯„ä¼°FOMAML-SFT
- [ ] ç”Ÿæˆå­¦ä¹ æ›²çº¿å›¾
- [ ] è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

### åˆ†æ
- [ ] è®¡ç®—æ ·æœ¬æ•ˆç‡
- [ ] åˆ†æè·¨ä»»åŠ¡æ³›åŒ–
- [ ] é”™è¯¯æ¡ˆä¾‹åˆ†æ
- [ ] ç”Ÿæˆå®éªŒæŠ¥å‘Š
- [ ] å‡†å¤‡å¯è§†åŒ–ç»“æœ

---

## ä¸‹ä¸€æ­¥

å®ŒæˆåŸºç¡€å®éªŒåï¼Œå¯ä»¥æ¢ç´¢ï¼š

1. **æ›´å¤šä»»åŠ¡**ï¼šæ·»åŠ ç‰©ç†ã€åŒ–å­¦ç­‰ç§‘å­¦ä»»åŠ¡
2. **æ›´å¤§æ¨¡å‹**ï¼šLlama-3.2-3B, Llama-3.1-8B
3. **å®Œæ•´MAML**ï¼šå¯¹æ¯”FOMAML vs MAML
4. **Reptileå¯¹æ¯”**ï¼šå¯¹æ¯”ä¸‰ç§å…ƒå­¦ä¹ ç®—æ³•
5. **æ··åˆæ–¹æ³•**ï¼šReptile + LoRA
6. **ä»»åŠ¡è¯¾ç¨‹**ï¼šä»ç®€å•åˆ°å›°éš¾çš„ä»»åŠ¡é¡ºåº
7. **å¤šæ¨¡æ€**ï¼šæ·»åŠ å›¾åƒè¾“å…¥ï¼ˆgeometryå›¾å½¢é¢˜ï¼‰

---

ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€
