# FOMAML-SFT æ•°æ®å‡†å¤‡å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒæ•°æ®æ ¼å¼](#æ ¸å¿ƒæ•°æ®æ ¼å¼)
2. [å¿…éœ€å­—æ®µè¯´æ˜](#å¿…éœ€å­—æ®µè¯´æ˜)
3. [Support-Query Splitæ„å»º](#support-query-splitæ„å»º)
4. [å®é™…æ“ä½œæ­¥éª¤](#å®é™…æ“ä½œæ­¥éª¤)
5. [æ•°æ®æ ¼å¼ç¤ºä¾‹](#æ•°æ®æ ¼å¼ç¤ºä¾‹)
6. [éªŒè¯å’Œè°ƒè¯•](#éªŒè¯å’Œè°ƒè¯•)

---

## ğŸ¯ æ ¸å¿ƒæ•°æ®æ ¼å¼

### æœ€ç»ˆæ•°æ®æ ¼å¼ï¼ˆverlå…¼å®¹ï¼‰

FOMAML-SFTè®­ç»ƒéœ€è¦çš„æ•°æ®æ ¼å¼æ˜¯**parquetæ–‡ä»¶**ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š

```python
{
    'prompt': str,      # ç”¨æˆ·è¾“å…¥/é—®é¢˜ï¼ˆå¿…éœ€ï¼‰
    'response': str,    # æ¨¡å‹å›ç­”ï¼ˆå¿…éœ€ï¼‰
    'metadata': str,    # å…ƒæ•°æ®ï¼ŒJSONå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰
}
```

### æ–‡ä»¶ç»„ç»‡ç»“æ„

```
data/
â”œâ”€â”€ meta_train/                    # å…ƒè®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ task1_support.parquet     # ä»»åŠ¡1çš„supporté›†
â”‚   â”œâ”€â”€ task1_query.parquet       # ä»»åŠ¡1çš„queryé›†
â”‚   â”œâ”€â”€ task2_support.parquet     # ä»»åŠ¡2çš„supporté›†
â”‚   â”œâ”€â”€ task2_query.parquet       # ä»»åŠ¡2çš„queryé›†
â”‚   â””â”€â”€ ...
â”œâ”€â”€ few_shot_eval/                 # Few-shotè¯„ä¼°æ•°æ®
â”‚   â”œâ”€â”€ task1_test.parquet
â”‚   â”œâ”€â”€ task1_5shot.parquet
â”‚   â”œâ”€â”€ task1_10shot.parquet
â”‚   â””â”€â”€ ...
â””â”€â”€ baseline_sft/                  # Baseline SFTæ•°æ®ï¼ˆå¯é€‰ï¼‰
    â””â”€â”€ mixed_train.parquet        # æ‰€æœ‰ä»»åŠ¡æ··åˆ
```

---

## ğŸ“ å¿…éœ€å­—æ®µè¯´æ˜

### 1. `prompt` å­—æ®µï¼ˆå¿…éœ€ï¼‰

**ä½œç”¨**ï¼šç”¨æˆ·çš„è¾“å…¥ï¼Œæ¨¡å‹çœ‹åˆ°çš„é—®é¢˜

**æ ¼å¼è¦æ±‚**ï¼š
- ç±»å‹ï¼šå­—ç¬¦ä¸²ï¼ˆstrï¼‰
- å¯ä»¥åŒ…å«ï¼šé—®é¢˜æè¿°ã€ä¸Šä¸‹æ–‡ã€æŒ‡ä»¤ç­‰
- æ”¯æŒå¤šè½®å¯¹è¯ï¼ˆä½¿ç”¨chat templateï¼‰

**ç¤ºä¾‹**ï¼š
```python
prompt = """è¯·è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ã€‚è¯·æä¾›è¯¦ç»†çš„è§£é¢˜æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆã€‚

é—®é¢˜ï¼šæ±‚è§£æ–¹ç¨‹ 2x + 5 = 13

è¯·ä¸€æ­¥æ­¥æ¨ç†å¹¶ç»™å‡ºç­”æ¡ˆã€‚"""
```

**é‡è¦æç¤º**ï¼š
- âš ï¸ Promptéƒ¨åˆ†åœ¨è®­ç»ƒæ—¶ä¼šè¢«**maskedæ‰**ï¼ˆä¸è®¡ç®—lossï¼‰
- âœ… åªæœ‰responseéƒ¨åˆ†è®¡ç®—loss
- è¿™æ˜¯verl SFTçš„æ ‡å‡†åšæ³•

### 2. `response` å­—æ®µï¼ˆå¿…éœ€ï¼‰

**ä½œç”¨**ï¼šæ¨¡å‹åº”è¯¥ç”Ÿæˆçš„å›ç­”

**æ ¼å¼è¦æ±‚**ï¼š
- ç±»å‹ï¼šå­—ç¬¦ä¸²ï¼ˆstrï¼‰
- åº”åŒ…å«å®Œæ•´çš„æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
- æ¨èä½¿ç”¨Chain-of-Thoughtæ ¼å¼

**ç¤ºä¾‹**ï¼š
```python
response = """è®©æˆ‘æ¥ä¸€æ­¥æ­¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

æ­¥éª¤1ï¼šç§»é¡¹
2x + 5 = 13
2x = 13 - 5
2x = 8

æ­¥éª¤2ï¼šæ±‚è§£
x = 8 / 2
x = 4

å› æ­¤ï¼Œç­”æ¡ˆæ˜¯ x = 4"""
```

**è®­ç»ƒè¡Œä¸º**ï¼š
- âœ… Responseéƒ¨åˆ†**è®¡ç®—loss**
- æ¨¡å‹å­¦ä¹ ç”Ÿæˆè¿™æ ·çš„å›ç­”
- ä½¿ç”¨masked cross-entropy loss

### 3. `metadata` å­—æ®µï¼ˆå¯é€‰ä½†æ¨èï¼‰

**ä½œç”¨**ï¼šå­˜å‚¨é¢å¤–ä¿¡æ¯ï¼Œç”¨äºåˆ†æå’Œè°ƒè¯•

**æ ¼å¼è¦æ±‚**ï¼š
- ç±»å‹ï¼šJSONå­—ç¬¦ä¸²ï¼ˆstrï¼‰
- å†…å®¹ï¼šä»»æ„é”®å€¼å¯¹

**ç¤ºä¾‹**ï¼š
```python
metadata = json.dumps({
    'source': 'MATH',           # æ•°æ®æ¥æº
    'subject': 'algebra',       # å­¦ç§‘/ä»»åŠ¡
    'level': 'Level 3',         # éš¾åº¦
    'original_id': '12345',     # åŸå§‹æ•°æ®ID
})
```

**æ¨èåŒ…å«çš„å­—æ®µ**ï¼š
```python
{
    'source': str,      # æ•°æ®æ¥æºï¼ˆMATH, GSM8Kç­‰ï¼‰
    'subject': str,     # ä»»åŠ¡/å­¦ç§‘
    'level': str,       # éš¾åº¦çº§åˆ«ï¼ˆå¯é€‰ï¼‰
    'task_id': str,     # ä»»åŠ¡æ ‡è¯†ç¬¦
}
```

---

## ğŸ”§ Support-Query Splitæ„å»º

### æ¦‚å¿µè¯´æ˜

FOMAMLéœ€è¦å°†æ¯ä¸ªä»»åŠ¡çš„æ•°æ®åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š

```
ä»»åŠ¡æ•°æ®
  â”œâ”€â”€ Support Set (æ”¯æŒé›†)
  â”‚   â””â”€â”€ ç”¨äºå†…å¾ªç¯é€‚åº”ï¼ˆinner loop adaptationï¼‰
  â”‚       æ¨¡å‹åœ¨è¿™äº›æ•°æ®ä¸Šå¿«é€Ÿå¾®è°ƒKæ­¥
  â”‚
  â””â”€â”€ Query Set (æŸ¥è¯¢é›†)
      â””â”€â”€ ç”¨äºå…ƒæŸå¤±è®¡ç®—ï¼ˆmeta lossï¼‰
          è¯„ä¼°é€‚åº”åçš„æ¨¡å‹æ€§èƒ½
```

### æ•°æ®åˆ’åˆ†æ¯”ä¾‹

#### æ¨èé…ç½®ï¼ˆFOMAMLå…¨å‚æ•°ï¼‰

```python
support_ratio = 0.20-0.30    # 20-30% ç”¨äºsupport
query_ratio = 0.30-0.40      # 30-40% ç”¨äºquery
test_ratio = 0.30-0.50       # 30-50% ä¿ç•™ç”¨äºè¯„ä¼°

# ç¤ºä¾‹ï¼šå¦‚æœæŸä»»åŠ¡æœ‰1000ä¸ªæ ·æœ¬
support: 300 samples  (30%)  # å†…å¾ªç¯é€‚åº”
query:   400 samples  (40%)  # å…ƒæŸå¤±è®¡ç®—
test:    300 samples  (30%)  # Few-shotè¯„ä¼°
```

#### æ ·æœ¬æ•°é‡å»ºè®®

| ä»»åŠ¡ç±»å‹ | Supportæ ·æœ¬æ•° | Queryæ ·æœ¬æ•° | æ€»æ ·æœ¬æ•° |
|---------|--------------|------------|---------|
| ç®€å•ä»»åŠ¡ | 200-300 | 300-450 | 600-900 |
| ä¸­ç­‰ä»»åŠ¡ | 300-500 | 450-750 | 900-1500 |
| å¤æ‚ä»»åŠ¡ | 500-800 | 750-1200 | 1500-2400 |

**æ³¨æ„**ï¼š
- Supportä¸è¦å¤ªå°‘ï¼ˆ<200å¯èƒ½ä¸å¤Ÿé€‚åº”ï¼‰
- Queryè¦æ¯”Supportå¤šï¼ˆç¡®ä¿å…ƒæŸå¤±ç¨³å®šï¼‰
- æ€»æ•°ä¸è¦å¤ªå¤šï¼ˆæ¯ä¸ªä»»åŠ¡>3000æ ·æœ¬å¯èƒ½è¿‡æ‹Ÿåˆï¼‰

### åˆ’åˆ†ç­–ç•¥

#### ç­–ç•¥1: éšæœºåˆ’åˆ†ï¼ˆæ¨èç”¨äºåŒè´¨ä»»åŠ¡ï¼‰

```python
import random

def split_data_random(examples, support_ratio=0.3, query_ratio=0.4):
    """éšæœºåˆ’åˆ†æ•°æ®"""
    random.shuffle(examples)

    n_total = len(examples)
    n_support = int(n_total * support_ratio)
    n_query = int(n_total * query_ratio)

    support = examples[:n_support]
    query = examples[n_support:n_support + n_query]
    test = examples[n_support + n_query:]

    return support, query, test
```

#### ç­–ç•¥2: åˆ†å±‚åˆ’åˆ†ï¼ˆæ¨èç”¨äºæœ‰éš¾åº¦çº§åˆ«çš„æ•°æ®ï¼‰

```python
def split_data_stratified(examples, support_ratio=0.3, query_ratio=0.4):
    """æŒ‰éš¾åº¦åˆ†å±‚åˆ’åˆ†ï¼Œç¡®ä¿å„é›†åˆéš¾åº¦åˆ†å¸ƒä¸€è‡´"""
    from collections import defaultdict

    # æŒ‰éš¾åº¦åˆ†ç»„
    by_level = defaultdict(list)
    for ex in examples:
        level = ex.get('level', 'unknown')
        by_level[level].append(ex)

    support, query, test = [], [], []

    # å¯¹æ¯ä¸ªéš¾åº¦çº§åˆ«ç‹¬ç«‹åˆ’åˆ†
    for level, level_examples in by_level.items():
        random.shuffle(level_examples)
        n = len(level_examples)
        n_support = int(n * support_ratio)
        n_query = int(n * query_ratio)

        support.extend(level_examples[:n_support])
        query.extend(level_examples[n_support:n_support + n_query])
        test.extend(level_examples[n_support + n_query:])

    return support, query, test
```

#### ç­–ç•¥3: æ—¶é—´åˆ’åˆ†ï¼ˆæ¨èç”¨äºæ—¶åºæ•°æ®ï¼‰

```python
def split_data_temporal(examples, support_ratio=0.3, query_ratio=0.4):
    """æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†ï¼ˆä¸æ‰“ä¹±ï¼‰"""
    # å‡è®¾exampleså·²æŒ‰æ—¶é—´æ’åº
    n_total = len(examples)
    n_support = int(n_total * support_ratio)
    n_query = int(n_total * query_ratio)

    support = examples[:n_support]
    query = examples[n_support:n_support + n_query]
    test = examples[n_support + n_query:]

    return support, query, test
```

### é‡è¦åŸåˆ™

âœ… **DOï¼ˆæ¨èåšæ³•ï¼‰**ï¼š
- Supportå’ŒQueryæ¥è‡ªåŒä¸€ä»»åŠ¡/åˆ†å¸ƒ
- Queryæ¯”Supportç¨å¤šï¼ˆæä¾›æ›´ç¨³å®šçš„å…ƒæ¢¯åº¦ï¼‰
- ä¿ç•™è¶³å¤Ÿçš„Testæ•°æ®ç”¨äºè¯„ä¼°
- ç¡®ä¿æ•°æ®è´¨é‡ï¼ˆå»é‡ã€æ¸…æ´—ï¼‰

âŒ **DON'Tï¼ˆé¿å…ï¼‰**ï¼š
- Supportå’ŒQueryæ•°æ®æ³„éœ²ï¼ˆé‡å¤æ ·æœ¬ï¼‰
- Supportå¤ªå°‘ï¼ˆ<100æ ·æœ¬å¯èƒ½ä¸å¤Ÿï¼‰
- Queryå¤ªå°‘ï¼ˆ<150æ ·æœ¬å…ƒæ¢¯åº¦ä¸ç¨³å®šï¼‰
- æ‰€æœ‰ä»»åŠ¡çš„Support/Queryæ¯”ä¾‹å·®å¼‚è¿‡å¤§

---

## ğŸš€ å®é™…æ“ä½œæ­¥éª¤

### æ­¥éª¤1: å‡†å¤‡åŸå§‹æ•°æ®

#### æ–¹æ¡ˆA: ä»å…¬å¼€æ•°æ®é›†ï¼ˆæ¨èç”¨äºå¿«é€Ÿå¼€å§‹ï¼‰

```bash
# ä½¿ç”¨ç°æœ‰è„šæœ¬è‡ªåŠ¨å‡†å¤‡MATHã€GSM8Kã€ScienceQAæ•°æ®
python prepare_math_science_data.py \
    --output-dir ./data/math_science_meta \
    --support-ratio 0.30 \
    --query-ratio 0.40 \
    --seed 42

# è¿™ä¼šè‡ªåŠ¨ï¼š
# 1. ä¸‹è½½æ•°æ®é›†
# 2. æŒ‰ä»»åŠ¡åˆ†ç»„
# 3. ç”Ÿæˆsupport/query split
# 4. ä¿å­˜ä¸ºparquetæ ¼å¼
```

#### æ–¹æ¡ˆB: ä½¿ç”¨è‡ªå·±çš„æ•°æ®

**åŸå§‹æ•°æ®æ ¼å¼ï¼ˆä»»æ„æ ¼å¼å‡å¯ï¼‰**ï¼š

```python
# ç¤ºä¾‹ï¼šJSONæ ¼å¼
your_raw_data = [
    {
        "question": "ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ",
        "answer": "å…‰åˆä½œç”¨æ˜¯æ¤ç‰©åˆ©ç”¨å…‰èƒ½...",
        "category": "biology",
        "difficulty": "easy"
    },
    {
        "question": "è®¡ç®—åœ†çš„é¢ç§¯å…¬å¼æ˜¯ä»€ä¹ˆï¼Ÿ",
        "answer": "åœ†çš„é¢ç§¯å…¬å¼æ˜¯ A = Ï€rÂ²...",
        "category": "math",
        "difficulty": "medium"
    },
    # ... æ›´å¤šæ•°æ®
]

# æˆ–CSVæ ¼å¼
# question,answer,category,difficulty
# "ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ","å…‰åˆä½œç”¨æ˜¯æ¤ç‰©åˆ©ç”¨å…‰èƒ½...","biology","easy"
# ...

# æˆ–ä»»ä½•ä½ å–œæ¬¢çš„æ ¼å¼ï¼
```

### æ­¥éª¤2: æŒ‰ä»»åŠ¡åˆ†ç»„

```python
from collections import defaultdict

def group_by_task(raw_data, task_key='category'):
    """æŒ‰ä»»åŠ¡å­—æ®µåˆ†ç»„"""
    tasks = defaultdict(list)

    for item in raw_data:
        task_name = item.get(task_key, 'default')
        tasks[task_name].append(item)

    return tasks

# ä½¿ç”¨
tasks = group_by_task(your_raw_data, task_key='category')

print(f"Found {len(tasks)} tasks:")
for task_name, examples in tasks.items():
    print(f"  {task_name}: {len(examples)} examples")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
Found 3 tasks:
  biology: 450 examples
  math: 680 examples
  physics: 520 examples
```

### æ­¥éª¤3: æ ¼å¼è½¬æ¢

åˆ›å»ºæ ¼å¼è½¬æ¢å‡½æ•°ï¼Œå°†åŸå§‹æ ¼å¼è½¬ä¸ºverlæ ¼å¼ï¼š

```python
import json

def format_example(raw_example):
    """
    å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºverl SFTæ ¼å¼

    å¿…é¡»è¿”å›: {'prompt': str, 'response': str, 'metadata': str}
    """
    # æå–å­—æ®µ
    question = raw_example['question']
    answer = raw_example['answer']
    category = raw_example.get('category', 'unknown')
    difficulty = raw_example.get('difficulty', 'unknown')

    # æ„å»ºpromptï¼ˆåŠ å…¥æŒ‡ä»¤ï¼‰
    prompt = f"""è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œæä¾›è¯¦ç»†è§£é‡Šã€‚

é—®é¢˜ï¼š{question}

è¯·æä¾›ç­”æ¡ˆå’Œè§£é‡Šã€‚"""

    # æ„å»ºresponse
    response = answer

    # æ„å»ºmetadata
    metadata = json.dumps({
        'source': 'my_dataset',
        'category': category,
        'difficulty': difficulty,
    })

    return {
        'prompt': prompt,
        'response': response,
        'metadata': metadata,
    }

# æµ‹è¯•
test_example = {
    'question': 'ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ',
    'answer': 'å…‰åˆä½œç”¨æ˜¯æ¤ç‰©åˆ©ç”¨å…‰èƒ½...',
    'category': 'biology',
    'difficulty': 'easy'
}

formatted = format_example(test_example)
print(formatted)
```

### æ­¥éª¤4: ç”ŸæˆSupport-Query Splitå¹¶ä¿å­˜

```python
import pandas as pd
from pathlib import Path

def create_support_query_split(
    task_name,
    examples,
    output_dir,
    support_ratio=0.30,
    query_ratio=0.40,
    format_func=format_example
):
    """ä¸ºå•ä¸ªä»»åŠ¡åˆ›å»ºsupport-query split"""
    import random

    # 1. æ‰“ä¹±æ•°æ®
    random.shuffle(examples)

    # 2. è®¡ç®—åˆ’åˆ†ç‚¹
    n_total = len(examples)
    n_support = int(n_total * support_ratio)
    n_query = int(n_total * query_ratio)

    # 3. åˆ’åˆ†
    support_examples = examples[:n_support]
    query_examples = examples[n_support:n_support + n_query]
    test_examples = examples[n_support + n_query:]

    print(f"\n{task_name}:")
    print(f"  Total: {n_total}")
    print(f"  Support: {len(support_examples)}")
    print(f"  Query: {len(query_examples)}")
    print(f"  Test: {len(test_examples)}")

    # 4. æ ¼å¼è½¬æ¢
    support_data = [format_func(ex) for ex in support_examples]
    query_data = [format_func(ex) for ex in query_examples]
    test_data = [format_func(ex) for ex in test_examples]

    # 5. è½¬æ¢ä¸ºDataFrame
    support_df = pd.DataFrame(support_data)
    query_df = pd.DataFrame(query_data)
    test_df = pd.DataFrame(test_data)

    # 6. ä¿å­˜ä¸ºparquet
    output_dir = Path(output_dir)
    (output_dir / "meta_train").mkdir(parents=True, exist_ok=True)
    (output_dir / "few_shot_eval").mkdir(parents=True, exist_ok=True)

    support_path = output_dir / "meta_train" / f"{task_name}_support.parquet"
    query_path = output_dir / "meta_train" / f"{task_name}_query.parquet"
    test_path = output_dir / "few_shot_eval" / f"{task_name}_test.parquet"

    support_df.to_parquet(support_path, index=False)
    query_df.to_parquet(query_path, index=False)
    test_df.to_parquet(test_path, index=False)

    print(f"  âœ… Saved: {support_path}")
    print(f"  âœ… Saved: {query_path}")
    print(f"  âœ… Saved: {test_path}")

    return support_df, query_df, test_df

# ä¸ºæ‰€æœ‰ä»»åŠ¡ç”Ÿæˆæ•°æ®
output_dir = "./data/my_meta_learning"

for task_name, task_examples in tasks.items():
    create_support_query_split(
        task_name=task_name,
        examples=task_examples,
        output_dir=output_dir,
        support_ratio=0.30,
        query_ratio=0.40,
        format_func=format_example
    )
```

### æ­¥éª¤5: åˆ›å»ºé…ç½®æ–‡ä»¶

åˆ›å»ºYAMLé…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®šæ•°æ®è·¯å¾„ï¼š

```yaml
# config_my_fomaml.yaml

model:
  partial_pretrain: "meta-llama/Llama-3.2-1B"
  use_fsdp: true
  enable_gradient_checkpointing: true

data:
  max_length: 2048
  prompt_key: "prompt"
  response_key: "response"

meta:
  use_fomaml: true

  inner_lr: 1e-4
  num_inner_steps: 5
  inner_batch_size: 4

  outer_lr: 3e-5
  meta_batch_size: 4
  query_batch_size: 4

  tasks:
    - name: "biology"
      support_files: ["./data/my_meta_learning/meta_train/biology_support.parquet"]
      query_files: ["./data/my_meta_learning/meta_train/biology_query.parquet"]
      support_max_samples: 300
      query_max_samples: 450

    - name: "math"
      support_files: ["./data/my_meta_learning/meta_train/math_support.parquet"]
      query_files: ["./data/my_meta_learning/meta_train/math_query.parquet"]
      support_max_samples: 300
      query_max_samples: 450

    - name: "physics"
      support_files: ["./data/my_meta_learning/meta_train/physics_support.parquet"]
      query_files: ["./data/my_meta_learning/meta_train/physics_query.parquet"]
      support_max_samples: 300
      query_max_samples: 450

trainer:
  total_steps: 5000
  save_freq: 500
  test_freq: 100
  project_name: "my-fomaml-experiment"
  experiment_name: "biology-math-physics"
  default_local_dir: "./checkpoints/my_fomaml"
```

---

## ğŸ“Š æ•°æ®æ ¼å¼ç¤ºä¾‹

### ç¤ºä¾‹1: æ•°å­¦æ¨ç†ä»»åŠ¡

**åŸå§‹æ•°æ®**ï¼š
```json
{
    "problem": "Solve for x: 2x + 5 = 13",
    "solution": "2x = 13 - 5 = 8, so x = 4",
    "level": "Level 2",
    "type": "Algebra"
}
```

**è½¬æ¢åï¼ˆverlæ ¼å¼ï¼‰**ï¼š
```python
{
    "prompt": """è¯·è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ã€‚è¯·æä¾›è¯¦ç»†çš„è§£é¢˜æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆã€‚

é—®é¢˜ï¼šSolve for x: 2x + 5 = 13

è¯·ä¸€æ­¥æ­¥æ¨ç†å¹¶ç»™å‡ºç­”æ¡ˆã€‚""",

    "response": """è®©æˆ‘æ¥ä¸€æ­¥æ­¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

æ­¥éª¤1ï¼šç§»é¡¹
2x + 5 = 13
2x = 13 - 5
2x = 8

æ­¥éª¤2ï¼šæ±‚è§£
x = 8 / 2
x = 4

å› æ­¤ï¼Œç­”æ¡ˆæ˜¯ x = 4""",

    "metadata": '{"source": "MATH", "level": "Level 2", "type": "Algebra"}'
}
```

### ç¤ºä¾‹2: ç§‘å­¦é—®ç­”ä»»åŠ¡

**åŸå§‹æ•°æ®**ï¼š
```json
{
    "question": "What is photosynthesis?",
    "answer": "Photosynthesis is the process by which plants use sunlight to produce glucose from carbon dioxide and water.",
    "subject": "biology",
    "difficulty": "medium"
}
```

**è½¬æ¢å**ï¼š
```python
{
    "prompt": """Please answer the following science question with a detailed explanation.

Question: What is photosynthesis?

Please provide your answer with reasoning.""",

    "response": """Photosynthesis is the process by which plants use sunlight to produce glucose from carbon dioxide and water.

This process occurs in the chloroplasts of plant cells and involves two main stages:
1. Light-dependent reactions
2. Light-independent reactions (Calvin cycle)

The overall equation is: 6COâ‚‚ + 6Hâ‚‚O + light â†’ Câ‚†Hâ‚â‚‚Oâ‚† + 6Oâ‚‚""",

    "metadata": '{"source": "biology_dataset", "subject": "biology", "difficulty": "medium"}'
}
```

### ç¤ºä¾‹3: ä»£ç ç”Ÿæˆä»»åŠ¡

**åŸå§‹æ•°æ®**ï¼š
```json
{
    "instruction": "Write a function to reverse a string",
    "input": "",
    "output": "def reverse_string(s):\n    return s[::-1]",
    "language": "python"
}
```

**è½¬æ¢å**ï¼š
```python
{
    "prompt": """è¯·æ ¹æ®ä»¥ä¸‹æŒ‡ä»¤ç¼–å†™ä»£ç ã€‚

æŒ‡ä»¤ï¼šWrite a function to reverse a string

è¯·æä¾›å®Œæ•´çš„ä»£ç å®ç°å’Œç®€è¦è¯´æ˜ã€‚""",

    "response": """ä¸‹é¢æ˜¯å®ç°ä»£ç ï¼š

```python
def reverse_string(s):
    return s[::-1]
```

è¯´æ˜ï¼š
- ä½¿ç”¨Pythonçš„åˆ‡ç‰‡è¯­æ³• [::-1] å¯ä»¥åè½¬å­—ç¬¦ä¸²
- æ—¶é—´å¤æ‚åº¦: O(n)
- ç©ºé—´å¤æ‚åº¦: O(n)""",

    "metadata": '{"source": "code_dataset", "language": "python", "task": "string_manipulation"}'
}
```

---

## âœ… éªŒè¯å’Œè°ƒè¯•

### éªŒè¯è„šæœ¬

åˆ›å»ºéªŒè¯è„šæœ¬æ£€æŸ¥æ•°æ®è´¨é‡ï¼š

```python
# validate_data.py

import pandas as pd
from pathlib import Path
import json

def validate_parquet_file(file_path):
    """éªŒè¯å•ä¸ªparquetæ–‡ä»¶"""
    print(f"\n=== Validating {file_path.name} ===")

    # 1. åŠ è½½æ•°æ®
    try:
        df = pd.read_parquet(file_path)
        print(f"âœ… Loaded successfully: {len(df)} rows")
    except Exception as e:
        print(f"âŒ Failed to load: {e}")
        return False

    # 2. æ£€æŸ¥å¿…éœ€åˆ—
    required_columns = ['prompt', 'response']
    for col in required_columns:
        if col not in df.columns:
            print(f"âŒ Missing required column: {col}")
            return False
        print(f"âœ… Column '{col}' exists")

    # 3. æ£€æŸ¥ç©ºå€¼
    for col in required_columns:
        null_count = df[col].isnull().sum()
        if null_count > 0:
            print(f"âš ï¸  Column '{col}' has {null_count} null values")
        else:
            print(f"âœ… Column '{col}' has no null values")

    # 4. æ£€æŸ¥æ•°æ®ç±»å‹
    for col in required_columns:
        if df[col].dtype != 'object':
            print(f"âš ï¸  Column '{col}' type is {df[col].dtype}, expected string")

    # 5. æ£€æŸ¥æ ·æœ¬é•¿åº¦
    prompt_lens = df['prompt'].str.len()
    response_lens = df['response'].str.len()

    print(f"\nPrompt length stats:")
    print(f"  Min: {prompt_lens.min()}")
    print(f"  Max: {prompt_lens.max()}")
    print(f"  Mean: {prompt_lens.mean():.1f}")

    print(f"\nResponse length stats:")
    print(f"  Min: {response_lens.min()}")
    print(f"  Max: {response_lens.max()}")
    print(f"  Mean: {response_lens.mean():.1f}")

    # 6. æ£€æŸ¥metadataæ ¼å¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'metadata' in df.columns:
        print(f"\nMetadata validation:")
        valid_json = 0
        for i, meta in enumerate(df['metadata'].head(10)):
            try:
                json.loads(meta)
                valid_json += 1
            except:
                print(f"  âš ï¸  Row {i}: Invalid JSON in metadata")
        print(f"  âœ… {valid_json}/10 samples have valid JSON metadata")

    # 7. æ‰“å°ç¤ºä¾‹
    print(f"\n--- Sample (first row) ---")
    print(f"Prompt:\n{df['prompt'].iloc[0][:200]}...")
    print(f"\nResponse:\n{df['response'].iloc[0][:200]}...")

    return True

def validate_task(task_name, data_dir):
    """éªŒè¯å•ä¸ªä»»åŠ¡çš„supportå’Œqueryæ•°æ®"""
    print(f"\n{'='*60}")
    print(f"Validating task: {task_name}")
    print(f"{'='*60}")

    data_dir = Path(data_dir)

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    support_file = data_dir / "meta_train" / f"{task_name}_support.parquet"
    query_file = data_dir / "meta_train" / f"{task_name}_query.parquet"

    if not support_file.exists():
        print(f"âŒ Support file not found: {support_file}")
        return False
    if not query_file.exists():
        print(f"âŒ Query file not found: {query_file}")
        return False

    # éªŒè¯æ¯ä¸ªæ–‡ä»¶
    validate_parquet_file(support_file)
    validate_parquet_file(query_file)

    # æ£€æŸ¥supportå’Œqueryçš„æ¯”ä¾‹
    support_df = pd.read_parquet(support_file)
    query_df = pd.read_parquet(query_file)

    print(f"\n--- Split Statistics ---")
    print(f"Support samples: {len(support_df)}")
    print(f"Query samples: {len(query_df)}")
    print(f"Ratio (query/support): {len(query_df)/len(support_df):.2f}")

    if len(query_df) < len(support_df):
        print("âš ï¸  Warning: Query set is smaller than support set")
        print("   Recommended: Query >= Support")

    return True

# ä½¿ç”¨
if __name__ == "__main__":
    data_dir = "./data/my_meta_learning"

    # éªŒè¯æ‰€æœ‰ä»»åŠ¡
    tasks = ["biology", "math", "physics"]

    for task in tasks:
        validate_task(task, data_dir)
```

### è¿è¡ŒéªŒè¯

```bash
python validate_data.py
```

**æœŸæœ›è¾“å‡º**ï¼š
```
============================================================
Validating task: biology
============================================================

=== Validating biology_support.parquet ===
âœ… Loaded successfully: 300 rows
âœ… Column 'prompt' exists
âœ… Column 'response' exists
âœ… Column 'prompt' has no null values
âœ… Column 'response' has no null values

Prompt length stats:
  Min: 120
  Max: 850
  Mean: 285.3

Response length stats:
  Min: 80
  Max: 650
  Mean: 220.5

--- Split Statistics ---
Support samples: 300
Query samples: 450
Ratio (query/support): 1.50
âœ… All checks passed!
```

### å¸¸è§é—®é¢˜æ’æŸ¥

#### é—®é¢˜1: "Missing required column"

**åŸå› **ï¼šparquetæ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—

**è§£å†³**ï¼š
```python
# æ£€æŸ¥ä½ çš„formatå‡½æ•°æ˜¯å¦è¿”å›äº†æ‰€æœ‰å¿…éœ€å­—æ®µ
def format_example(ex):
    return {
        'prompt': ...,     # âœ… å¿…éœ€
        'response': ...,   # âœ… å¿…éœ€
        'metadata': ...,   # â­• å¯é€‰
    }
```

#### é—®é¢˜2: "Query set is smaller than support set"

**åŸå› **ï¼šQueryæ¯”Supportå°‘ï¼Œå¯èƒ½å¯¼è‡´å…ƒæ¢¯åº¦ä¸ç¨³å®š

**è§£å†³**ï¼š
```python
# è°ƒæ•´æ¯”ä¾‹
create_support_query_split(
    support_ratio=0.25,  # å‡å°‘support
    query_ratio=0.45,    # å¢åŠ query
)
```

#### é—®é¢˜3: Promptæˆ–Responseå¤ªçŸ­

**åŸå› **ï¼šæ ¼å¼è½¬æ¢æ—¶ä¸¢å¤±äº†ä¿¡æ¯

**è§£å†³**ï¼š
```python
# ç¡®ä¿promptåŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡
prompt = f"""[æŒ‡ä»¤]

é—®é¢˜ï¼š{question}

[è¦æ±‚ç­”æ¡ˆæ ¼å¼]"""  # æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡

# ç¡®ä¿responseåŒ…å«å®Œæ•´ç­”æ¡ˆ
response = f"""[æ¨ç†è¿‡ç¨‹]

{reasoning}

[æœ€ç»ˆç­”æ¡ˆ]
{answer}"""
```

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹æ¨¡æ¿

### å®Œæ•´çš„æ•°æ®å‡†å¤‡è„šæœ¬æ¨¡æ¿

```python
# my_data_preparation.py

import json
import random
import pandas as pd
from pathlib import Path

# ============================================
# Step 1: åŠ è½½ä½ çš„åŸå§‹æ•°æ®
# ============================================
def load_your_data():
    """åŠ è½½ä½ çš„åŸå§‹æ•°æ®ï¼ˆä»»æ„æ ¼å¼ï¼‰"""
    # TODO: æ›¿æ¢ä¸ºä½ çš„æ•°æ®åŠ è½½é€»è¾‘

    # ç¤ºä¾‹ï¼šä»JSONåŠ è½½
    # with open('your_data.json') as f:
    #     data = json.load(f)

    # ç¤ºä¾‹ï¼šä»CSVåŠ è½½
    # import pandas as pd
    # df = pd.read_csv('your_data.csv')
    # data = df.to_dict('records')

    # è¿”å›æ ¼å¼ï¼šlist of dicts
    return [
        {'question': '...', 'answer': '...', 'task': '...'},
        # ...
    ]

# ============================================
# Step 2: æŒ‰ä»»åŠ¡åˆ†ç»„
# ============================================
def group_by_task(data, task_key='task'):
    """æŒ‰ä»»åŠ¡åˆ†ç»„"""
    from collections import defaultdict
    tasks = defaultdict(list)
    for item in data:
        task_name = item.get(task_key, 'default')
        tasks[task_name].append(item)
    return dict(tasks)

# ============================================
# Step 3: æ ¼å¼è½¬æ¢å‡½æ•°
# ============================================
def format_example(raw_example):
    """
    å°†ä½ çš„åŸå§‹æ ¼å¼è½¬æ¢ä¸ºverlæ ¼å¼

    TODO: æ ¹æ®ä½ çš„æ•°æ®ä¿®æ”¹è¿™ä¸ªå‡½æ•°
    """
    # æå–å­—æ®µï¼ˆæ ¹æ®ä½ çš„æ•°æ®ç»“æ„ä¿®æ”¹ï¼‰
    question = raw_example['question']
    answer = raw_example['answer']

    # æ„å»ºprompt
    prompt = f"""è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ç­”æ¡ˆã€‚"""

    # æ„å»ºresponse
    response = answer

    # æ„å»ºmetadata
    metadata = json.dumps({
        'source': 'my_dataset',
        'task': raw_example.get('task', 'unknown'),
    })

    return {
        'prompt': prompt,
        'response': response,
        'metadata': metadata,
    }

# ============================================
# Step 4: Support-Queryåˆ’åˆ†
# ============================================
def create_splits(task_name, examples, output_dir,
                 support_ratio=0.30, query_ratio=0.40):
    """åˆ›å»ºsupport-query split"""
    random.shuffle(examples)

    n = len(examples)
    n_support = int(n * support_ratio)
    n_query = int(n * query_ratio)

    support = examples[:n_support]
    query = examples[n_support:n_support + n_query]
    test = examples[n_support + n_query:]

    # æ ¼å¼è½¬æ¢
    support_data = [format_example(ex) for ex in support]
    query_data = [format_example(ex) for ex in query]
    test_data = [format_example(ex) for ex in test]

    # ä¿å­˜
    output_dir = Path(output_dir)
    (output_dir / "meta_train").mkdir(parents=True, exist_ok=True)
    (output_dir / "few_shot_eval").mkdir(parents=True, exist_ok=True)

    pd.DataFrame(support_data).to_parquet(
        output_dir / "meta_train" / f"{task_name}_support.parquet",
        index=False
    )
    pd.DataFrame(query_data).to_parquet(
        output_dir / "meta_train" / f"{task_name}_query.parquet",
        index=False
    )
    pd.DataFrame(test_data).to_parquet(
        output_dir / "few_shot_eval" / f"{task_name}_test.parquet",
        index=False
    )

    print(f"âœ… {task_name}: support={len(support)}, query={len(query)}, test={len(test)}")

# ============================================
# Main: å®Œæ•´æµç¨‹
# ============================================
def main():
    # é…ç½®
    output_dir = "./data/my_fomaml_data"
    support_ratio = 0.30
    query_ratio = 0.40

    # 1. åŠ è½½æ•°æ®
    print("Loading data...")
    raw_data = load_your_data()
    print(f"Loaded {len(raw_data)} examples")

    # 2. æŒ‰ä»»åŠ¡åˆ†ç»„
    print("\nGrouping by task...")
    tasks = group_by_task(raw_data, task_key='task')
    for task_name, examples in tasks.items():
        print(f"  {task_name}: {len(examples)} examples")

    # 3. ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºsplits
    print("\nCreating support-query splits...")
    for task_name, examples in tasks.items():
        create_splits(
            task_name=task_name,
            examples=examples,
            output_dir=output_dir,
            support_ratio=support_ratio,
            query_ratio=query_ratio,
        )

    print(f"\nâœ… Done! Data saved to {output_dir}")
    print("\nNext steps:")
    print("1. Run validation: python validate_data.py")
    print("2. Update config YAML with data paths")
    print("3. Start training: python maml_sft_trainer.py")

if __name__ == "__main__":
    main()
```

**ä½¿ç”¨è¿™ä¸ªæ¨¡æ¿**ï¼š
1. ä¿®æ”¹ `load_your_data()` åŠ è½½ä½ çš„æ•°æ®
2. ä¿®æ”¹ `format_example()` é€‚é…ä½ çš„æ•°æ®æ ¼å¼
3. è¿è¡Œ `python my_data_preparation.py`

---

## ğŸ“š å‚è€ƒèµ„æº

- **ç¤ºä¾‹è„šæœ¬**ï¼š`prepare_math_science_data.py`ï¼ˆå®Œæ•´å®ç°ï¼‰
- **é…ç½®ç¤ºä¾‹**ï¼š`config_maml_sft_example.yaml`
- **éªŒè¯è„šæœ¬**ï¼šä¸Šé¢çš„`validate_data.py`

---

## âœ… æ£€æŸ¥æ¸…å•

å‡†å¤‡æ•°æ®å‰ç¡®è®¤ï¼š

- [ ] åŸå§‹æ•°æ®å·²å‡†å¤‡å¥½
- [ ] æ¯ä¸ªä»»åŠ¡è‡³å°‘æœ‰500+æ ·æœ¬
- [ ] æ•°æ®å·²æŒ‰ä»»åŠ¡åˆ†ç»„
- [ ] å®ç°äº†formatå‡½æ•°ï¼ˆåŸå§‹æ ¼å¼â†’verlæ ¼å¼ï¼‰
- [ ] è®¾ç½®äº†åˆç†çš„support/queryæ¯”ä¾‹
- [ ] åˆ›å»ºäº†è¾“å‡ºç›®å½•
- [ ] è¿è¡Œäº†æ•°æ®éªŒè¯è„šæœ¬
- [ ] æ›´æ–°äº†é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„

---

**å‡†å¤‡å¥½æ•°æ®åï¼Œå°±å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼** ğŸš€

```bash
# éªŒè¯æ•°æ®
python validate_data.py

# å¼€å§‹è®­ç»ƒ
torchrun --nproc_per_node=4 maml_sft_trainer.py --config-name config_my_fomaml
```
