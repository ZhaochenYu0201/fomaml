# MAML-SFT Configuration Example
# This configuration file demonstrates how to set up meta-learning for LLM SFT

# Model Configuration
model:
  partial_pretrain: "meta-llama/Llama-3.2-1B"  # Or your model path
  trust_remote_code: true
  use_fsdp: true
  enable_gradient_checkpointing: true

  fsdp_config:
    wrap_policy:
      transformer_layer_cls_to_wrap: "LlamaDecoderLayer"  # Adjust based on your model
    model_dtype: "bf16"
    cpu_offload: false

  # ⚠️ 重要说明：此FOMAML实现是全参数优化，不使用LoRA！
  # 如果需要LoRA版本的元学习，请参考META-LORA实现（meta_lora_trainer.py）
  # 下面的LoRA配置仅作为保留项，不会被当前实现使用
  # lora_rank: 8
  # lora_alpha: 16
  # target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]

# Data Configuration
data:
  max_length: 2048
  truncation: "right"
  prompt_key: "prompt"
  response_key: "response"
  use_shm: false
  shuffle: true
  seed: 42

  # Padding configuration
  pad_mode: "no_padding"  # or "padding"
  use_dynamic_bsz: false
  balance_dp_token: true

# Meta-Learning Configuration
meta:
  # MAML/FOMAML settings
  use_fomaml: true  # Set to false for full MAML (slower but potentially better)

  # Inner loop (task adaptation)
  inner_lr: 1e-4  # Learning rate for task adaptation (α)
  num_inner_steps: 5  # Number of gradient steps on support set (K)
  inner_batch_size: 4  # Batch size for support set

  # Outer loop (meta-learning)
  outer_lr: 3e-5  # Learning rate for meta-updates (β)
  meta_batch_size: 4  # Number of tasks per meta-update
  query_batch_size: 4  # Batch size for query set

  # Task definitions
  # Each task should have support and query datasets
  tasks:
    - name: "medical"
      support_files: ["data/medical/support.parquet"]
      query_files: ["data/medical/query.parquet"]
      support_max_samples: 1000
      query_max_samples: 500

    - name: "legal"
      support_files: ["data/legal/support.parquet"]
      query_files: ["data/legal/query.parquet"]
      support_max_samples: 1000
      query_max_samples: 500

    - name: "coding"
      support_files: ["data/coding/support.parquet"]
      query_files: ["data/coding/query.parquet"]
      support_max_samples: 1000
      query_max_samples: 500

    - name: "math"
      support_files: ["data/math/support.parquet"]
      query_files: ["data/math/query.parquet"]
      support_max_samples: 1000
      query_max_samples: 500

# Optimizer Configuration
optim:
  optimizer_type: "AdamW"
  lr: 3e-5  # This is the outer_lr
  weight_decay: 0.01
  betas: [0.9, 0.999]
  clip_grad: 1.0

  # Learning rate schedule
  lr_scheduler: "cosine"
  lr_warmup_steps_ratio: 0.1

# Trainer Configuration
trainer:
  device: "cuda"
  total_steps: 10000  # Total meta-training steps
  save_freq: 500  # Save checkpoint every N steps
  test_freq: 100  # Evaluate every N steps

  # Logging
  project_name: "maml-llm-sft"
  experiment_name: "llama-3.2-1b-multi-domain"
  logger: "wandb"  # or "tensorboard"

  # Checkpoint paths
  default_local_dir: "./checkpoints/maml_sft"
  default_hdfs_dir: null  # Optional HDFS path

  # Resume settings
  resume_mode: "auto"  # "auto", "disable", or "resume_path"
  resume_from_path: null
  max_ckpt_to_keep: 5

# Checkpoint Configuration
checkpoint:
  save_contents: ["model", "optimizer"]
  load_contents: ["model", "optimizer"]
