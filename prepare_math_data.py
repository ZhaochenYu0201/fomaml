"""
MATHæ•°æ®é›†å‡†å¤‡è„šæœ¬ - FOMAMLè®­ç»ƒä¸“ç”¨

åŠŸèƒ½ï¼š
1. ä¸‹è½½å’ŒåŠ è½½MATHæ•°æ®é›†
2. æŒ‰æ•°å­¦é¢†åŸŸåˆ’åˆ†ä»»åŠ¡ï¼ˆä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ç­‰ï¼‰
3. ç”Ÿæˆsupport/query splitç”¨äºmeta-training
4. ä¿å­˜ä¸ºparquetæ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python prepare_math_data.py --output-dir ./data/math_meta --support-ratio 0.30
"""

import os
import json
import argparse
import random
from pathlib import Path
from typing import Dict, List
from collections import defaultdict

import pandas as pd
import numpy as np
from datasets import load_dataset
from tqdm import tqdm


def prepare_math_dataset(
    output_dir: str,
    support_ratio: float = 0.30,
    query_ratio: float = 0.40,
    seed: int = 42,
    max_samples_per_task: int = -1,
):
    """
    å‡†å¤‡MATHæ•°æ®é›†ç”¨äºFOMAMLè®­ç»ƒ

    Args:
        output_dir: è¾“å‡ºç›®å½•
        support_ratio: Supporté›†æ¯”ä¾‹
        query_ratio: Queryé›†æ¯”ä¾‹
        seed: éšæœºç§å­
        max_samples_per_task: æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆ-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ï¼‰
    """
    random.seed(seed)
    np.random.seed(seed)

    output_path = Path(output_dir)
    (output_path / "meta_train").mkdir(parents=True, exist_ok=True)
    (output_path / "few_shot_eval").mkdir(parents=True, exist_ok=True)

    print("=" * 60)
    print("MATHæ•°æ®é›†å‡†å¤‡ - FOMAMLè®­ç»ƒ")
    print("=" * 60)

    # åŠ è½½MATHæ•°æ®é›†
    print("\nğŸ“¥ æ­£åœ¨åŠ è½½MATHæ•°æ®é›†...")
    try:
        dataset = load_dataset("hendrycks/competition_math", split="train")
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        print("\nè§£å†³æ–¹æ¡ˆï¼š")
        print("1. ç¡®ä¿å·²å®‰è£…: pip install datasets")
        print("2. æˆ–æ‰‹åŠ¨ä¸‹è½½: https://github.com/hendrycks/math")
        return

    # æŒ‰æ•°å­¦é¢†åŸŸåˆ†ç»„
    print("\nğŸ“Š æŒ‰æ•°å­¦é¢†åŸŸåˆ†ç»„...")
    tasks = defaultdict(list)
    for example in tqdm(dataset, desc="åˆ†ç»„ä¸­"):
        subject = example['type']  # 'Algebra', 'Geometry', 'Number Theory', etc.
        tasks[subject].append(example)

    print(f"\næ‰¾åˆ° {len(tasks)} ä¸ªæ•°å­¦é¢†åŸŸï¼š")
    for subject, examples in sorted(tasks.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"  ğŸ“Œ {subject}: {len(examples)} ä¸ªé—®é¢˜")

    # ä¸ºæ¯ä¸ªé¢†åŸŸåˆ›å»ºsupport/query/test split
    print(f"\nğŸ”„ åˆ›å»ºæ•°æ®åˆ’åˆ† (support={support_ratio:.0%}, query={query_ratio:.0%})...")

    task_summary = []

    for subject, examples in tasks.items():
        task_name = subject.lower().replace(' ', '_')

        # å¯é€‰ï¼šé™åˆ¶æ ·æœ¬æ•°
        if max_samples_per_task > 0 and len(examples) > max_samples_per_task:
            examples = random.sample(examples, max_samples_per_task)

        # æ‰“ä¹±æ•°æ®
        random.shuffle(examples)

        # è®¡ç®—åˆ’åˆ†ç‚¹
        n_total = len(examples)
        n_support = int(n_total * support_ratio)
        n_query = int(n_total * query_ratio)

        # åˆ’åˆ†æ•°æ®
        support_examples = examples[:n_support]
        query_examples = examples[n_support:n_support + n_query]
        test_examples = examples[n_support + n_query:]

        # æ ¼å¼è½¬æ¢
        support_data = [format_math_example(ex) for ex in support_examples]
        query_data = [format_math_example(ex) for ex in query_examples]
        test_data = [format_math_example(ex) for ex in test_examples]

        # ä¿å­˜ä¸ºparquet
        support_path = output_path / "meta_train" / f"{task_name}_support.parquet"
        query_path = output_path / "meta_train" / f"{task_name}_query.parquet"
        test_path = output_path / "few_shot_eval" / f"{task_name}_test.parquet"

        pd.DataFrame(support_data).to_parquet(support_path, index=False)
        pd.DataFrame(query_data).to_parquet(query_path, index=False)
        pd.DataFrame(test_data).to_parquet(test_path, index=False)

        task_summary.append({
            'task': task_name,
            'support': len(support_data),
            'query': len(query_data),
            'test': len(test_data),
            'total': n_total
        })

        print(f"  âœ… {task_name:20s} â†’ support={len(support_data):4d}, query={len(query_data):4d}, test={len(test_data):4d}")

    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    summary_df = pd.DataFrame(task_summary)
    summary_path = output_path / "dataset_summary.csv"
    summary_df.to_csv(summary_path, index=False)

    print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    print(summary_df.to_string(index=False))
    print(f"\nğŸ’¾ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜è‡³: {summary_path}")

    # ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿
    generate_config_template(output_path, task_summary)

    print("\n" + "=" * 60)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ æ•°æ®ä¿å­˜ä½ç½®: {output_path.absolute()}")
    print(f"ğŸ“ é…ç½®æ¨¡æ¿: {output_path / 'config_template.yaml'}")
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"  1. æ£€æŸ¥é…ç½®: {output_path / 'config_template.yaml'}")
    print(f"  2. å¼€å§‹è®­ç»ƒ: torchrun --nproc_per_node=4 maml_sft_trainer.py")


def format_math_example(example: Dict) -> Dict:
    """
    å°†MATHæ•°æ®é›†æ ·æœ¬è½¬æ¢ä¸ºverl SFTæ ¼å¼

    Args:
        example: MATHæ•°æ®é›†åŸå§‹æ ·æœ¬

    Returns:
        verlæ ¼å¼çš„æ ·æœ¬
    """
    problem = example['problem']
    solution = example['solution']
    level = example['level']
    subject = example['type']

    # æ„å»ºpromptï¼ˆå¸¦æŒ‡ä»¤ï¼‰
    prompt = f"""è¯·è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ã€‚è¯·æä¾›è¯¦ç»†çš„è§£é¢˜æ­¥éª¤ï¼Œå¹¶åœ¨æœ€åç”¨ \\boxed{{}} æ ‡æ³¨æœ€ç»ˆç­”æ¡ˆã€‚

é—®é¢˜ï¼š{problem}

è¯·ä¸€æ­¥æ­¥æ¨ç†å¹¶ç»™å‡ºç­”æ¡ˆã€‚"""

    # responseå°±æ˜¯å®Œæ•´çš„è§£ç­”
    response = solution

    # metadataï¼ˆæ–¹ä¾¿åç»­åˆ†æï¼‰
    metadata = json.dumps({
        'source': 'MATH',
        'subject': subject,
        'level': level,
    })

    return {
        'prompt': prompt,
        'response': response,
        'metadata': metadata,
    }


def generate_config_template(output_dir: Path, task_summary: List[Dict]):
    """ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿"""

    config_template = f"""# FOMAML-SFT é…ç½®æ–‡ä»¶
# è‡ªåŠ¨ç”Ÿæˆäº: {pd.Timestamp.now()}

model:
  partial_pretrain: "ä½ çš„æ¨¡å‹è·¯å¾„"  # ä¾‹å¦‚: "./models/Qwen2.5-7B-Instruct"
  trust_remote_code: true
  use_fsdp: true
  enable_gradient_checkpointing: true

  fsdp_config:
    wrap_policy:
      transformer_layer_cls_to_wrap: "Qwen2DecoderLayer"  # Qwenæ¨¡å‹ä½¿ç”¨æ­¤é…ç½®
    model_dtype: "bf16"
    cpu_offload: false

data:
  max_length: 2048
  truncation: "right"
  prompt_key: "prompt"
  response_key: "response"

meta:
  use_fomaml: true

  # å†…å¾ªç¯å‚æ•°
  inner_lr: 1.0e-4
  num_inner_steps: 5
  inner_batch_size: 4

  # å¤–å¾ªç¯å‚æ•°
  outer_lr: 3.0e-5
  meta_batch_size: 4
  query_batch_size: 4

  # ä»»åŠ¡å®šä¹‰
  tasks:
"""

    for task_info in task_summary:
        task_name = task_info['task']
        config_template += f"""    - name: "{task_name}"
      support_files: ["{output_dir}/meta_train/{task_name}_support.parquet"]
      query_files: ["{output_dir}/meta_train/{task_name}_query.parquet"]
      support_max_samples: {task_info['support']}
      query_max_samples: {task_info['query']}

"""

    config_template += """
optim:
  optimizer_type: "AdamW"
  lr: 3.0e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]
  clip_grad: 1.0

  lr_scheduler: "cosine"
  lr_warmup_steps_ratio: 0.1

trainer:
  device: "cuda"
  total_steps: 5000
  save_freq: 500
  test_freq: 100

  # Wandbé…ç½®
  project_name: "fomaml-math"
  experiment_name: "qwen-math-meta-learning"
  logger: "wandb"

  default_local_dir: "./checkpoints/fomaml_math"
"""

    config_path = output_dir / "config_template.yaml"
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(config_template)

    print(f"\nâœ… é…ç½®æ¨¡æ¿å·²ç”Ÿæˆ: {config_path}")


def validate_dataset(file_path: Path):
    """éªŒè¯parquetæ–‡ä»¶æ ¼å¼"""
    try:
        df = pd.read_parquet(file_path)

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['prompt', 'response']
        missing = [col for col in required_cols if col not in df.columns]

        if missing:
            print(f"âŒ {file_path.name}: ç¼ºå°‘åˆ— {missing}")
            return False

        # æ£€æŸ¥ç©ºå€¼
        null_counts = df[required_cols].isnull().sum()
        if null_counts.any():
            print(f"âš ï¸  {file_path.name}: å­˜åœ¨ç©ºå€¼\n{null_counts}")

        print(f"âœ… {file_path.name}: {len(df)} ä¸ªæ ·æœ¬, æ ¼å¼æ­£ç¡®")
        return True

    except Exception as e:
        print(f"âŒ {file_path.name}: è¯»å–å¤±è´¥ - {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="å‡†å¤‡MATHæ•°æ®é›†ç”¨äºFOMAMLè®­ç»ƒ")
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./data/math_meta",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--support-ratio",
        type=float,
        default=0.30,
        help="Supporté›†æ¯”ä¾‹ (é»˜è®¤: 0.30)"
    )
    parser.add_argument(
        "--query-ratio",
        type=float,
        default=0.40,
        help="Queryé›†æ¯”ä¾‹ (é»˜è®¤: 0.40)"
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=-1,
        help="æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§æ ·æœ¬æ•° (-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­ (é»˜è®¤: 42)"
    )
    parser.add_argument(
        "--validate",
        action="store_true",
        help="æ•°æ®å‡†å¤‡å®ŒæˆåéªŒè¯æ•°æ®æ ¼å¼"
    )

    args = parser.parse_args()

    # å‡†å¤‡æ•°æ®
    prepare_math_dataset(
        output_dir=args.output_dir,
        support_ratio=args.support_ratio,
        query_ratio=args.query_ratio,
        seed=args.seed,
        max_samples_per_task=args.max_samples,
    )

    # éªŒè¯æ•°æ®
    if args.validate:
        print("\n" + "=" * 60)
        print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
        print("=" * 60)

        output_path = Path(args.output_dir)
        all_valid = True

        for parquet_file in (output_path / "meta_train").glob("*.parquet"):
            if not validate_dataset(parquet_file):
                all_valid = False

        if all_valid:
            print("\nâœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡ï¼")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æ•°æ®æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ã€‚")


if __name__ == "__main__":
    main()
